{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Cancer Genomics","text":""},{"location":"#the-university-of-sydney","title":"The University of Sydney","text":""},{"location":"#25th-27th-july-2017","title":"25th - 27th July 2017","text":"<p>The Cancer Genomics workshop aims to provide an introduction to cancer genomics analytical pipelines for single nucleotide variations (SNV), copy number variations (CNV) and structural variations (SV).</p>"},{"location":"#workshop-content","title":"Workshop Content","text":"<p>By the end of the course participants will be able to: \u2022 Ability to perform NGS alignment and manipulate the output, \u2022 Consider and plan experimental design,  \u2022 Be able to identify and generate variants (SNV, CNV, SV, Indels),  \u2022 Interpret variants with potential clinical interest, \u2022 Be able to visualise and present data</p> <p>This workshop will be delivered using a mixture of lectures, hands-on practical sessions, and open discussions.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This workshop was developed by Bioplatforms Australia, in partnership with CSIRO, and with support from the European Bioinformatics Institute (EBI), a member of the European Molecular Biology Laboratory (EMBL) in the UK. The workshop content has been maintained and updated by a network of dedicated [bioinformatics trainers] (http://www.bioplatforms.com/bioinformatics-training/) from around Australia.</p> <p>The Bioinformatics Training Platform was developed in collaboration with the Monash Bioinformatics Platform and this workshop has been hosted on Interset infrastructure.</p> <p>This workshop is possible thanks to funding support from the NSW Office of Health and Medical Research and the Commonwealth Government National Collaborative Research Infrastructure Strategy (NCRIS).</p>"},{"location":"license/","title":"License","text":"<p>This work is licensed under a Creative Commons Attribution 3.0 Unported License and the below text is a summary of the main terms of the full Legal Code (the full license) available at http://creativecommons.org/licenses/by/3.0/legalcode.</p> <p>You are free: </p> <ul> <li>to copy, distribute, display, and perform the work  </li> <li>to make derivative works  </li> <li>to make commercial use of the work  </li> </ul> <p>Under the following conditions: </p> <ul> <li>Attribution - You must give the original author credit.</li> </ul> <p>With the understanding that:</p> <ul> <li>Waiver - Any of the above conditions can be waived if you get permission from the copyright holder.</li> <li>Public Domain - Where the work or any of its elements is in the public domain under applicable law, that status is in no way affected by the license.</li> <li> <p>Other Rights - In no way are any of the following rights affected by the license:</p> <ul> <li>Your fair dealing or fair use rights, or other applicable copyright exceptions and limitations;  </li> <li>The author\u2019s moral rights;  </li> <li>Rights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights.  </li> </ul> </li> <li> <p>Notice - For any reuse or distribution, you must make clear to others the license terms of this work.</p> </li> </ul>"},{"location":"preamble/","title":"Workshop Information","text":""},{"location":"preamble/#providing-feedback","title":"Providing Feedback","text":"<p>While we endeavour to deliver a workshop with quality content and documentation in a venue conducive to an exciting, well run hands-on workshop with a bunch of knowledgeable and likable trainers, we know there are things we could do better.</p> <p>Whilst we want to know what didn\u2019t quite hit the mark for you, what would be most helpful and least depressing, would be for you to provide ways to improve the workshop. i.e. constructive feedback. After all, if we knew something wasn\u2019t going to work, we wouldn\u2019t have done it or put it into the workshop in the first place! Remember, we\u2019re experts in the field of bioinformatics not experts in the field of biology!</p> <p>Clearly, we also want to know what we did well! This gives us that \u201cfeel good\u201d factor which will see us through those long days and nights in the lead up to such hands-on workshops!</p> <p>With that in mind, we\u2019ll provide three really high tech mechanism through which you can provide anonymous feedback during the workshop:</p> <ol> <li> <p>A sheet of paper, from a flip-chart, sporting a \u201chappy\u201d face and a \u201cnot so happy\u201d face. Armed with a stack of colourful post-it notes, your mission is to see how many comments you can stick on the \u201chappy\u201d side!</p> </li> <li> <p>Some empty ruled pages at the back of this handout. Use them for your own personal notes or for write specific comments/feedback about the workshop as it progresses.</p> </li> <li> <p>An online post-workshop evaluation survey. We\u2019ll ask you to complete this before you leave. If you\u2019ve used the blank pages at the back of this handout to make feedback notes, you\u2019ll be able to provide more specific and helpful feedback with the least amount of brain-drain!</p> </li> </ol>"},{"location":"preamble/#document-structure","title":"Document Structure","text":"<p>We have provided you with an electronic copy of the workshop\u2019s hands-on tutorial documents. We have done this for two reasons: 1) you will have something to take away with you at the end of the workshop, and 2) you can save time (mis)typing commands on the command line by using copy-and-paste.</p>  <p>While you could fly through the hands-on sessions doing copy-and-paste you will learn more if you take the time, saved from not having to type all those commands, to understand what each command is doing!</p>  <p>The commands to enter at a terminal look something like this:</p> <pre><code>tophat --solexa-quals -g 2 --library-type fr-unstranded -j annotation/Danio_rerio.Zv9.66.spliceSites -o tophat/ZV9_2cells genome/ZV9 data/2cells_1.fastq data/2cells_2.fastq\n</code></pre> <p>The following styled code is not to be entered at a terminal, it is simply to show you the syntax of the command. You must use your own judgement to substitute in the correct arguments, options, filenames etc</p> <pre><code>tophat [options]* &lt;index_base&gt; &lt;reads_1&gt; &lt;reads_2&gt;\n</code></pre> <p>The following is an example how of R commands are styled:</p> <pre><code>R --no-save\nlibrary(plotrix)\ndata &lt;- read.table(\"run_25/stats.txt\", header=TRUE)\nweighted.hist(data$short1_cov+data$short2_cov, data$lgth, breaks=0:70)\nq()\n</code></pre> <p>The following icons are used throughout the documentation to help you navigate around the document more easily:</p>  <p>Question</p> <p>Questions to answer.</p>   <p>Answer</p> <p>Answers will be provided at the end of the workskop.</p>   <p>Important</p> <p>This is important. </p>   <p>STOP</p> <p>Warning - STOP and read.</p>   <p>Bonus exercise</p> <p>Bonus exercise for fast learners.</p>   <p>Advanced exercise</p> <p>Advanced exercise for super-fast learners</p>"},{"location":"preamble/#resources-used","title":"Resources Used","text":"<p>We have provided you with an environment which contains all the tools and data you need for the duration of this workshop. However, we also provide details about the tools and data used by each module at the start of the respective module documentation.</p>"},{"location":"modules/cancer-module-alignment/alignment/","title":"Read Alignment","text":""},{"location":"modules/cancer-module-alignment/alignment/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Perform the simple NGS data alignment task against reference data.</p> </li> <li> <p>Learn about the SAM/BAM formats for further manipulation.</p> </li> <li> <p>Be able to sort and index BAM format for visualisation purposes.</p> </li> </ul>"},{"location":"modules/cancer-module-alignment/alignment/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-alignment/alignment/#tools-used","title":"Tools Used","text":"<p>BWA Burrows-Wheeler Algorithm: http://bio-bwa.sourceforge.net</p> <p>Samtools: http://picard.sourceforge.net/</p>"},{"location":"modules/cancer-module-alignment/alignment/#useful-links","title":"Useful Links","text":"<p>SAM Specification: http://samtools.sourceforge.net/SAM1.pdf</p> <p>Explain SAM Flags: https://broadinstitute.github.io/picard/explain-flags.html</p>"},{"location":"modules/cancer-module-alignment/alignment/#sources-of-data","title":"Sources of Data","text":"<p>http://sra.dnanexus.com/studies/ERP001071</p>"},{"location":"modules/cancer-module-alignment/alignment/#author-information","title":"Author Information","text":"<p>Primary Author(s): Sonika Tyagi sonika.tyagi@agrf.org.au Gayle Philip gkphilip@unimelb.edu.au</p> <p>Contributor(s):</p>"},{"location":"modules/cancer-module-alignment/alignment/#introduction","title":"Introduction","text":"<p>The goal of this hands-on session is to perform an NGS alignment on the sequencing data coming from a tumour and normal group of samples. We will align raw sequencing data to the human genome using the BWA aligner and then we will discuss the sequence alignment and mapping format (SAM). SAM to BAM conversion, indexing and sorting will also be demonstrated. These are important and essential steps for downstream processing of the aligned BAM files.</p> <p>This data is the whole genome sequencing of a lung adenocarcinoma patient AK55. It was downloaded from <code>ERP001071</code>. Only the HiSeq2000 data for <code>Blood</code> and <code>liverMets</code> were analysed.</p> <p>Accession numbers associated with read data are assigned by the European Bioinformatics Institute (EBI) and start with \u2019ER\u2019. e.g. ERP is the study ID and ERR is the run ID. The original FASTQ files downloaded had the ERR number in front of each read name in the FASTQ file (e.g. @ERRxx HWI-ST478_xxxx). The read name had to be edited to remove the ERR number at the start of the name. This had caused problems for downstream programs such as Picard for marking optical duplicates.</p> <p>We have used 4 Blood samples (8 paired-end (PE) <code>*.fastq.gz</code> files) and 5 Liver samples (10 PE <code>*.fastq.gz</code> files) data from this study to perform the whole genome alignment using the BWA aligner. The whole process took &gt;150K CPU seconds per sample and the precomputed alignment will be used in different sections of this workshop.</p>"},{"location":"modules/cancer-module-alignment/alignment/#prepare-the-environment","title":"Prepare the Environment","text":"<p>By now you know about the raw sequence FASTQ format generated by the Illumina sequencers. Next we will see how FASTQ files are aligned to the reference genome and what the resulting standard alignment format is. In the interest of time, we have selected only 1 million paired reads from a <code>Blood</code> sample to demonstrate a <code>BWA</code> command. The remaining alignments have already been performed for you and will be required in the subsequent modules of the workshop.</p> <p>The input data for this section can be found in the <code>alignment</code> directory on your desktop. Please follow the commands below to go to the right folder and view the top 10 lines of the input FASTQ file:</p> <p>Open the Terminal.</p> <p>First, go to the right folder, where the data are stored.</p> <pre><code>cd /home/trainee/alignment\nls\nzless input/SM_Blood_ID_ERR059356.subset_R1.fastq.gz\n</code></pre> <p>Press <code>q</code> to stop the <code>zless</code> command.</p>"},{"location":"modules/cancer-module-alignment/alignment/#overview-of-the-process","title":"Overview of the Process","text":"<p>Figure 1: A flow diagram showing the steps that will be performed in this practical. </p>"},{"location":"modules/cancer-module-alignment/alignment/#alignment","title":"Alignment","text":"<p>You already know that there are a number of competing tools for short read alignment, each with its own set of strengths, weaknesses, and caveats. Here we will use <code>BWA</code>, a widely used aligner based on the Burrows-Wheeler Algorithm. The alignment involves two steps:  </p> <p>1) Indexing the genome. 2) Running the alignment command.  </p> <p>BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. It consists of three algorithms: BWA-backtrack, BWA-SW and BWA-MEM. The first algorithm is designed for Illumina sequence reads up to 100bp, while the other two are for longer sequences ranging from 70bp to 1Mbp. BWA-MEM and BWA-SW share similar features such as long-read support and split alignment, but BWA-MEM, which is the latest, is generally recommended for high-quality queries as it is faster and more accurate. BWA-MEM also has better performance than BWA-backtrack for 70-100bp Illumina reads. For more details see the BWA manual.</p> <p>BWA has a number of parameters in order to perform the alignment. To view them all, type</p> <pre><code>bwa &lt;press enter&gt;\n</code></pre> <p> BWA uses an indexed genome for the alignment in order to keep its memory footprint small. Indexing a genome is similar in concept to indexing a book. If you want to know on which page a certain word appears or a chapter begins, it is much more efficient/faster to look it up in a pre-built index than going through every page of the book until you find it. Indices allow the aligner to narrow down the potential origin of a query sequence within the genome, saving both time and memory.  </p> <p>Due to time constraints, we will NOT be running the indexing command. It is run only once for a version of a genome, and the complete command to index the human genome version hg19 is given below.</p>  <p>STOP</p> <p>You DO NOT need to run this command. This has already been run for you.</p> <p><code>bwa index -p bwaIndex/human_g1k_v37.fasta -a bwtsw human_g1k_v37.fasta</code></p>  <p>We have used the following arguments for the indexing of the genome.</p>  <p>-p:  Prefix of the output database [same as db filename].   -a:  Algorithm for constructing BWT index. This method works with the     whole human genome. Ref genome filename: the last argument is the name of the reference genome file in the fasta format.</p>  <p>This command will output 6 files that constitute the index. These files have the prefix <code>human_g1k_v37.fasta</code> and are stored in the <code>bwaIndex</code> subdirectory. To view the precomputed index files, type:</p> <pre><code>ls -l bwaIndex\n</code></pre> <p> Now that the genome is indexed we can move on to the actual alignment.  </p> <p>Make a directory to store the output from your aligner.</p> <pre><code>mkdir outputs\n</code></pre> <p>The first argument for <code>bwa</code> is the basename of the index for the genome to be searched. In our case this is <code>human_g1k_v37.fasta</code>.</p> <p>Align the reads from the <code>Blood</code> sample using the following command:</p> <pre><code>bwa mem -M -t 4 -R '@RG\\tSM:Blood\\tID:ERR059356.subset\\tLB:lb\\tPL:ILLUMINA' bwaIndex/human_g1k_v37.fasta input/SM_Blood_ID_ERR059356.subset_R1.fastq.gz input/SM_Blood_ID_ERR059356.subset_R2.fastq.gz &gt; outputs/SM_Blood_ID_ERR059356.subset.sam\n</code></pre> <p>The above command outputs the alignment in SAM format and stores them in the file <code>SM_Blood_ID_ERR059356.subset.sam</code> in the subdirectory <code>outputs</code>.</p> <p>We have used the following arguments for the alignment of the reads.</p>  <p>mem: fast mode of high quality input such the Illumina -M: flags extra hits as secondary. This is needed for compatibility with   other tools downstream. -t: Number of threads. -R: Complete read group header line.</p>  <p> The SAM (Sequence Alignment/Map) format is currently the de facto standard for storing large nucleotide sequence alignments. It is a TAB-delimited text format consisting of a header section, which is optional, and an alignment section. If present, the header must be prior to the alignments. Header lines start with <code>@</code>, while alignment lines do not. Each alignment line has 11 mandatory fields with essential alignment information such as mapping position.</p> <p>Navigate into your <code>outputs</code> directory and look at the top 10 lines of the SAM file by typing:</p> <pre><code>cd outputs\nhead -n 10 SM_Blood_ID_ERR059356.subset.sam\n</code></pre>   <p>Question</p> <p>Can you distinguish between the header of the SAM format and the actual alignments?</p>   Answer <p>The header line starts with the letter \u2018@\u2019 i.e. <pre><code>@SQ SN:GL000192.1   LN:547496\n@RG SM:Blood    ID:ERR059356    LB:lb   PL:ILLUMINA\n@PG ID:bwa  PN:bwa  VN:0.7.15-r1140 CL:bwa mem -M -t 4 -R @RG\\tSM:Blood\\tID:ERR059356.subset\\tLB:lb\\tPL:ILLUMINA bwaIndex/human_g1k_v37.fasta input/SM_Blood_ID_ERR059356.subset_R1.fastq.gz input/SM_Blood_ID_ERR059356.subset_R2.fastq.gz\n</code></pre></p> <p>The actual alignments start with read ID i.e. <pre><code>HWI-ST478_0133:3:1101:1374:2056#0   147 11\nHWI-ST478_0133:3:1101:1352:2070#0   163 14\n</code></pre></p>     <p>Question</p> <p>What kind of information does the header provide?</p>   Answer <ul> <li> <p>@HD: Header line; VN: Format version; SO: the sort order of     alignments.</p> </li> <li> <p>@SQ: Reference sequence information; SN: reference sequence name;     LN: reference sequence length.</p> </li> <li> <p>@PG: Program; ID: Program record identifier; VN: Program     version; CL: the command line that produces the alignment.</p> </li> </ul>     <p>Question</p> <p>To which chromosome are the reads mapped?</p>   Answer <p>All chromosomes are represented (look at the 3rd field). grep -v \u201c^@\u201d SM_Blood_ID_ERR059356.subset.sam  | cut -f3 | sort | uniq</p>"},{"location":"modules/cancer-module-alignment/alignment/#manipulating-sam-output","title":"Manipulating SAM output","text":"<p>SAM files are rather big and when dealing with a high volume of NGS data, storage space can become an issue. As we have already seen, we can convert SAM to BAM files (their binary equivalent that are not human readable) that occupy much less space.</p> <p>Convert SAM to BAM using <code>samtools view</code> and store the output in the file <code>SM_Blood_ID_ERR059356.subset.bam</code>. You have to instruct <code>samtools view</code> that the input is in SAM format (<code>-S</code>), the output should be in BAM format (<code>-b</code>) and that you want the output to be stored in the file specified by the <code>-o</code> option:</p> <pre><code>samtools view -bSo SM_Blood_ID_ERR059356.subset.bam SM_Blood_ID_ERR059356.subset.sam\n</code></pre> <p>BAM files are not human-readable but can be viewed with the <code>samtools view</code> command.</p>   <p>Advanced exercise<p>Compute summary stats for the Flag values associated with the alignments  using:  <pre><code>samtools flagstat SM_Blood_ID_ERR059356.subset.bam\n</code></pre></p> </p>"},{"location":"modules/cancer-module-alignment/alignment/#post-alignment-visualisation-option","title":"Post Alignment Visualisation option","text":"<p>IGV is a stand-alone genome browser that can be used to visualise the BAM outputs. Please check their website for all the formats that IGV can display.</p> <p>We will be using IGV later in the workshop for viewing a BAM file in the genome browser. It requires the index of the BAM file to be in the same folder as where the BAM file is. The index file should have the same name as the BAM file and the suffix <code>.bai</code>. Finally, to create the index of a BAM file you need to make sure that the file is sorted according to chromosomal coordinates.</p> <p>Sort alignments according to chromosomal position and store the result in the file with the prefix <code>SM_Blood_ID_ERR059356.subset.sorted</code>:</p> <pre><code>samtools sort SM_Blood_ID_ERR059356.subset.bam SM_Blood_ID_ERR059356.subset.sorted\n</code></pre> <p> Index the sorted file.</p> <pre><code>samtools index SM_Blood_ID_ERR059356.subset.sorted.bam\n</code></pre> <p>The indexing will create a file called <code>SM_Blood_ID_ERR059356.subset.sorted.bam.bai</code>. Note that you don\u2019t have to specify the name of the index file when running <code>samtools index</code>, it simply appends a <code>.bai</code> suffix to the input BAM file. </p>  <p>Question</p> <p>How can you quickly find out whether a BAM file is already coordinate sorted or not?</p>   Answer <p>Use <code>samtools view -h</code> command to look at the SAM header. It will have an SO field (e.g. SO:coordinate)</p>"},{"location":"modules/cancer-module-cli/commandline/","title":"Introduction to Command Line","text":""},{"location":"modules/cancer-module-cli/commandline/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Familiarise yourself with the command line environment on a Linux     operating system.</p> </li> <li> <p>Run some basic linux system and file operation commands</p> </li> <li> <p>Navigation of biological data files structure and manipulation</p> </li> </ul>"},{"location":"modules/cancer-module-cli/commandline/#resources","title":"Resources","text":""},{"location":"modules/cancer-module-cli/commandline/#tools","title":"Tools","text":"<ul> <li> <p>Basic Linux system commands on an Ubuntu OS.</p> </li> <li> <p>Basic file operation commands</p> </li> </ul>"},{"location":"modules/cancer-module-cli/commandline/#links","title":"Links","text":"<ul> <li> <p>Software Carpentry</p> </li> <li> <p>Example 1000Genome Project data</p> </li> </ul>"},{"location":"modules/cancer-module-cli/commandline/#author-information","title":"Author Information","text":"<p>Primary Author(s): Matt Field matt.field@anu.edu.au </p>"},{"location":"modules/cancer-module-cli/commandline/#shell-exercise","title":"Shell Exercise","text":"<p>Let\u2019s try out your new shell skills on some real data.</p> <p>The file <code>1000gp.vcf</code> is a small sample (1%) of a very large text file containing human genetics data. Specifically, it describes genetic variation in three African individuals sequenced as part of the 1000 Genomes Project. The \u2019vcf\u2019 extension lets us know that it\u2019s in a specific text format, namely \u2019Variant Call Format\u2019. The file starts with a bunch of comment lines (they start with \u2019#\u2019 or \u2019##\u2019), and then a large number of data lines. This VCF file lists the differences between the three African individuals and a standard \u2019individual\u2019 called the reference (actually based upon a few different people). Each line in the file corresponds to a difference. The line tells us the position of the difference (chromosome and position), the genetic sequence in the reference, and the corresponding sequence in each of the three Africans. Before we start processing the file, let\u2019s get a high-level view of the file that we\u2019re about to work with.</p> <p>Open the Terminal and go to the directory where the data are stored: <pre><code>cd /home/trainee/cli\nls\npwd\nls -lh 1000gp.vcf\nwc -l 1000gp.vcf\n</code></pre></p>  <p>Question</p> <p>What is the file size (in kilo-bytes), and how many lines are in the file?.</p>   Hint <p><code>man ls</code>, <code>man wc</code></p>     Answer <p>3.6M</p> <p>45034 lines</p>    <p>Because this file is so large, you\u2019re going to almost always want to pipe (\u2018|\u2019) the result of any command to less (a simple text viewer, type <code>q</code> to exit) or head (to print the first 10 lines) so that you don\u2019t accidentally print 45,000 lines to the screen.</p> <p>Let\u2019s start by printing the first 5 lines to see what it looks like.   <pre><code>head -5 1000gp.vcf\n</code></pre></p> <p>That isn\u2019t very interesting; it\u2019s just a bunch of the comments at the beginning of the file (they all start with <code>#</code>)!</p> <p>Print the first 20 lines to see more of the file. <pre><code>head -20 1000gp.vcf\n</code></pre></p> <p>Okay, so now we can see the basic structure of the file. A few comment lines that start with \u2019#\u2019 or \u2019##\u2019 and then a bunch of lines of data that contain all the data and are pretty hard to understand. Each line of data contains the same number of fields, and all fields are separated with TABs. These fields are:</p> <ol> <li> <p>the chromosome (which volume the difference is in)</p> </li> <li> <p>the position (which character in the volume the difference starts     at)</p> </li> <li> <p>the ID of the difference</p> </li> <li> <p>the sequence in the reference human(s)</p> </li> </ol> <p>The rest of the columns tell us, in a rather complex way, a bunch of additional information about that position, including: the predicted sequence for each of the three Africans and how confident the scientists are that these sequences are correct.</p> <p>To start analyzing the actual data, we have to remove the header.</p>  <p>Question</p> <p>How can we print the first 10 non-header lines (those that don\u2019t start with a \u2019#\u2019)?</p>   Hint <p><code>man grep</code> (remember to use pipes \u2018|\u2019)</p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | head\n</code></pre>      <p>This is an advanced section. </p>   <p>Question</p> <p>How many lines of data are in the file (rather than counting the number of header lines and subtracting, try just counting the number of data lines)?</p>   Answer <pre><code>grep -v \"^#\" 1000gp.vcf | wc -l\n</code></pre> <p>(should print 45024)</p>    <p>Where these differences are located can be important. If all the differences between two encyclopedias were in just the first volume, that would be interesting. The first field of each data line is the name of the chromosome that the difference occurs on (which volume we\u2019re on).</p>  <p>Question</p> <p>Print the first 10 chromosomes, one per line.</p>   Hint <p><code>man cut</code> (remember to remove header lines first)</p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | cut -f 1 | head\n</code></pre>    <p>As you should have observed, the first 10 lines are on numbered chromosomes. Every normal cell in your body has 23 pairs of chromosomes, 22 pairs of \u2018autosomal\u2019 chromosomes (these are numbered 1-22) and a pair of sex chromosomes (two Xs if you\u2019re female, an X and a Y if you\u2019re male).</p> <p>Let\u2019s look at which chromosomes these variations are on.</p>  <p>Question</p> <p>Print a list of the chromosomes that are in the file (each chromosome name should only be printed once, so you should only print 23 lines).</p>   Hint <p>Remove all duplicates from your previous answer (<code>man sort</code>)</p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | cut -f 1 | sort -u\n</code></pre>    <p>Rather than using <code>sort</code> to print unique results, a common pipeline is to first sort and then pipe to another UNIX command, <code>uniq</code>. The <code>uniq</code> command takes sorted input and prints only unique lines, but it provides more flexibility than just using sort by itself. Keep in mind, if the input isn\u2019t sorted, <code>uniq</code> won\u2019t work properly.</p>  <p>Question</p> <p>Using <code>sort</code> and <code>uniq</code>, print the number of times each chromosome occurs in the file.</p>   Hint <p><code>man uniq</code></p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | cut -f 1 | sort | uniq -c\n</code></pre>     <p>Question</p> <p>Add to your previous solution to list the chromosomes from most frequently observed to least frequently observed.</p>   Hint <p>Make sure you\u2019re sorting in descending order. By default, <code>sort</code> sorts in ascending order.</p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | cut -f 1 | sort | uniq -c | sort -n -r\n</code></pre>    <p>This is great, but biologists might also like to see the chromosomes ordered by their number (not dictionary order), since different chromosomes have different attributes and this ordering allows them to find a specific chromosome more easily.</p>  <p>Question</p> <p>Sort the previous output by chromosome number</p>   Hint <p>A lot of the power of sort comes from the fact that you can specify which fields to sort on, and the order in which to sort them. In this case you only need to sort on one field.</p>     Answer <pre><code>grep -v \"^#\" 1000gp.vcf | cut -f 1 | sort | uniq -c | sort -k 2n\n</code></pre>"},{"location":"modules/cancer-module-cnv/cnv-tut/","title":"Copy Number Variation","text":""},{"location":"modules/cancer-module-cnv/cnv-tut/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Understand and perform a simple copy number variation analysis on     NGS data</p> </li> <li> <p>Become familiar with Sequenza</p> </li> <li> <p>Understand the CNV inference process as an interplay between depth     of sequencing, cellularity and B-allele frequency</p> </li> <li> <p>Visualize CNV events by manual inspection</p> </li> </ul>"},{"location":"modules/cancer-module-cnv/cnv-tut/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-cnv/cnv-tut/#tools-used","title":"Tools Used","text":"<p>Sequenza: http://www.cbs.dtu.dk/biotools/sequenza/</p> <p>IGV: http://www.broadinstitute.org/igv/</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#sources-of-data","title":"Sources of Data","text":"<p>Raw data download: http://sra.dnanexus.com/studies/ERP001071</p> <p>Data publication: http://www.ncbi.nlm.nih.gov/pubmed/22194472</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#author-information","title":"Author Information","text":"<p>Primary Author(s): Velimir Gayevskiy, Garvan Institute v.gayevskiy@garvan.org.au Sonika Tyagi, AGRF sonika.tyagi@agrf.org.au </p> <p>Contributor(s): </p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#introduction","title":"Introduction","text":"<p>The goal of this hands-on session is to perform a copy number variation analysis (CNV) on a normal/tumour pair of alignment files (BAMs) produced by the mapping of Illumina short read sequencing data.</p> <p>To ensure reasonable analysis times, we will perform the analysis on a heavily subsetted pair of BAM files. These files contain just the first 60Mb of chromosome 5 but contain several examples of inferred copy number events to enable interpretation and visualisation of the copy number variation that is present in entire cancer genomes. <code>Sequenza</code> is the tool we will use to perform this analysis. It consists of two <code>Python</code> pre-processing steps followed by a third step in <code>R</code> to infer the depth ratio, cellularity, ploidy and to plot the results for interpretation.</p> <p>In the second part of the tutorial we will also be using <code>IGV</code> to visualise and manually inspect the copy number variation we inferred in the first part for validation purposes. This section will also include a discussion on the importance of good quality data by highlighting the inadequacies of the workshop dataset and the implications this has on analysis results.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#prepare-the-environment","title":"Prepare the Environment","text":"<p>We will use a dataset derived from whole genome sequencing of a 33-yr-old lung adenocarcinoma patient, who is a never-smoker and has no familial cancer history.</p> <p>The data files are contained in the subdirectory called <code>data</code> and are the following:</p>  <p><code>normal.chr5.60Mb.bam</code> and <code>normal.chr5.60Mb.bam.bai</code></p> <p><code>tumour.chr5.60Mb.bam</code> and <code>tumour.chr5.60Mb.bam.bai</code></p>  <p> These files are based on subsetting the whole genomes derived from <code>blood</code> and <code>liver metastases</code> to the first 60Mb of chromosome 5. This will allow our analyses to run in a sufficient time during the workshop, but it\u2019s worth being aware that we are analysing just 1.9% of the genome which will highlight the length of time and resources required to perform cancer genomics on full genomes!</p> <p>Open the Terminal and go to the <code>cnv</code> working directory:</p> <pre><code>cd /home/trainee/cnv/\n</code></pre>  <p>All commands entered into the terminal for this tutorial should be from within the <code>cnv</code> directory.</p>  <p>Check that the <code>data</code> directory contains the above-mentioned files by typing:</p> <pre><code>ls -l data\n</code></pre>"},{"location":"modules/cancer-module-cnv/cnv-tut/#sequenza-cnv-analysis","title":"Sequenza CNV Analysis","text":"<p>Sequenza is run in three steps. The first pre-processing step is run on the final normal and tumour mapped data (BAM files) in order to walk the genome in a pileup format (automatically generated by <code>samtools</code>). This first step finds high quality sites in the genomes and extracts their depth and genotype in the normal genome and calculates the variant alleles and allele frequencies in the tumour genome. The second step is to perform a binning on these sites to save space and analysis time in the third step. Finally, the third step is run in <code>R</code> to normalise the depth ratio between the normal/tumour genomes, infer cellularity and ploidy and graphically output results for interpretation.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#step-1-pre-processing-walking-the-genome","title":"Step 1: Pre-processing \u2013 Walking the Genome","text":"<pre><code>pypy software/sequenza/sequenza-utils.py bam2seqz \\\n-n data/normal.chr5.60Mb.bam \\\n-t data/tumour.chr5.60Mb.bam \\\n--fasta assets/human_g1k_v37.fasta \\\n-gc assets/human_g1k_v37.gc50Base.txt.gz \\\n-C 5:1-60000000 | gzip &gt; stage1.seqz.gz\n</code></pre>  <p>Hint</p> <p>Press tab after typing a few characters of a directory of filename to auto-complete the rest. This makes entering long file names very quick.</p>  <p>Explanation of parameters:</p>  <p>-n: the normal BAM -t: the tumour BAM --fasta: the reference genome used for mapping (b37 here) -gc: GC content as windows through the genome (pre-generated and downloadable from the Sequenza website) -C: specifies the genomic location to process  </p>    <p>There will not be any indication that it is running once you launch the command, to make sure it is running open a new Terminal tab with <code>Shift + Control + T</code> (or from the menu with File then Open Tab) and type the command <code>top</code>. You should see the top line being the command \u2019pypy\u2019 with a % CPU usage of 98/99%. Press <code>q</code> to quit out of this process view and go back to the tab running <code>Sequenza</code>. If everything is running correctly, it will take approximately 40 minutes to run. Go have a coffee!</p>  <p> Once the command is done you will be returned to the terminal prompt. Make sure the output file is the correct size by typing <code>ls -lh</code> from the Terminal window that you ran <code>Sequenza</code> from, there should be a file called <code>stage1.seqz.gz</code> of the size ~395M.</p> <p>You can look at the first few lines of the output in the file <code>stage1.seqz.gz</code> with:</p> <pre><code>zcat stage1.seqz.gz | head -n 20\n</code></pre> <p>This output has one line for each position in the BAMs and includes information on the position, depths, allele frequencies, zygosity, GC in the location.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#step-2-perform-binning","title":"Step 2: Perform Binning","text":"<p>The binning step takes the rows of genomic positions and compresses them down to 1 row for every 200 rows previously. This massively reduces the file size and processing time in the third step.</p> <pre><code>pypy software/sequenza/sequenza-utils.py seqz-binning \\\n-w 200 \\\n-s stage1.seqz.gz | gzip &gt; stage2.seqz.gz\n</code></pre> <p>Explanation of parameters:</p>  <p>-w: the window size (typically 50 for exomes, 200 for genomes) -s: the large seqz file generated in the first step</p>  <p>This step should take approximately 4 minutes to complete.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#step-3-running-sequenza-algorithms-and-plotting-results","title":"Step 3: Running Sequenza Algorithms and Plotting Results","text":"<p>We will now perform the CNV analysis and output the results using the <code>R</code> part of Sequenza.</p> <p>Open the <code>R</code> terminal:</p> <pre><code>R\n</code></pre> <p>You should now see the <code>R</code> prompt identified with \u201c&gt;\u201d.</p> <p>Run the Sequenza <code>R</code> commands:</p> <pre><code>library(\"sequenza\")\nsetwd(\"/home/trainee/cnv\")\ndata.file &lt;- \"stage2.seqz.gz\"\nseqzdata &lt;- sequenza.extract(data.file)\nCP.example &lt;- sequenza.fit(seqzdata)\nsequenza.results(sequenza.extract = seqzdata, cp.table = CP.example, sample.id = \"CanGenWorkshop\", out.dir=\"sequenza_results\")\n</code></pre> <p>Quit <code>R</code>:  </p> <pre><code>q()\n</code></pre> <p>Then enter <code>n</code> at the \u201cSave workspace image\u201d prompt.</p> <p>If every command ran successfully, you will now have a <code>sequenza_results</code> folder containing 13 files (type <code>ls -l sequenza_results/</code>).</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#sequenza-analysis-results-and-visualisation","title":"Sequenza Analysis Results and Visualisation","text":"<p>One of the first and most important estimates that Sequenza provides is the tumour cellularity (the estimated percentage of tumour cells in the tumour genome). This estimate is based on the B allele frequency and depth ratio through the genome and is an important metric to know for interpretation of Sequenza results and for other analyses. Lets look at the cellularity estimate for our analysis by opening <code>CanGenWorkshop_model_fit.pdf</code> with the command:</p> <pre><code>evince sequenza_results/CanGenWorkshop_model_fit.pdf\n</code></pre> <p> The cellularity estimate is at the top along with the average ploidy estimate and the standard deviation of the B allele frequency. We can see that the cellularity has been estimated at 24% which is fairly low and we will see why this is bad in the next section on CNV visualisation. The ploidy value of 2.1 indicates this piece of the genome is not hugely amplified or deleted and the BAF standard deviation indicates there are no significant long losses of heterozygosity.</p> <p>Close the PDF window to resume the Terminal prompt.</p> <p>Let\u2019s now look at the CNV inferences through our genomic block. Open the genome copy number visualisation file with:</p> <pre><code>evince sequenza_results/CanGenWorkshop_genome_view.pdf\n</code></pre> <p> This file contains three \u201cpages\u201d of copy number events through the entire genomic block.</p> <ol> <li>The first page shows copy numbers of the A (red) and B (blue) alleles,</li> <li>The second page shows overall copy number changes, and</li> <li>The third page shows the B allele frequency and depth ratio through genomic block.  </li> </ol> <p>Looking at the overall copy number changes, we see that our block is at a copy number of 2 with a small duplication to copy number 4 about \u2153 of the way through the block and another just after halfway through the block. There is also a reduction in copy number to 1 copy about \u2158 of the way through the block. The gap that you see just before this reduction in copy number is the chromosomal centromere - an area that is notoriously difficult to sequence so always ends up in a gap with short read data.</p> <p>You can see how this is a very easy to read output and lets you immediately see the frequency and severity of copy number events through your genome. Let\u2019s compare the small genomic block we ran with the same output from the entire genome which has been pre-computed for you. This is located in the <code>pre_generated/results_whole_genome</code> folder and contains the same 13 output files as for the small genomic block. As before, let\u2019s look at the cellularity estimate with:</p> <pre><code>evince pre_generated/results_whole_genome/CanGenWorkshop_model_fit.pdf\n</code></pre> <p> It now looks like it\u2019s even worse at just 16%! A change is to be expected as we were only analysing 1.9% of the genome. Let\u2019s now look at the whole genome copy number profile with:</p> <pre><code>evince pre_generated/results_whole_genome/CanGenWorkshop_genome_view.pdf\n</code></pre> <p> You can see that there are a number of copy number events across the genome and our genomic block (the first 60Mb of chromosome 5) is inferred as mostly copy number 4 followed by a reduction to copy number 2, rather than 2 to 1 as we saw in the output we generated. The reason for this is that <code>Sequenza</code> uses the genome-wide depth ratio and BAF in order to estimate copy number, if you ask it to analyse a small block mostly at copy number 4 with a small reduction to copy number 2, the most likely scenario in lieu of more data is that this is a copy number 2 block with a reduction to 1. It\u2019s important to carefully examine the cellularity, ploidy and BAF estimates of your sample along with the plots of model fit (<code>CanGenWorkshop_model_fit.pdf</code>) and cellularity/ploidy contours (<code>CanGenWorkshop_CP_contours.pdf</code>) in order to decide if you believe Sequenza\u2019s inference of the copy numbers. Have a look at these for yourself if you want to get a better idea of how <code>Sequenza</code> makes its inferences and conclusions.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#cnv-visualisationconfirmation-in-igv","title":"CNV Visualisation/Confirmation in IGV","text":"<p>Let\u2019s see if we can visualise one of the CNV events where copy number increased significantly. We\u2019ll focus on the copy number 4 event seen at about \u2153 of the way through the <code>CanGenWorkshop_genome_view.pdf</code> output we generated. First, we need to find the coordinates that have been predicted for this event. Have a look at the <code>CanGenWorkshop_segments.txt</code> file in the results folder to view all predicted CNV events with:</p> <pre><code>less sequenza_results/CanGenWorkshop_segments.txt\n</code></pre> <p> There is only one at a copy number of 4 (CNt column) and it starts at 21,051,700 to 21,522,065 which is 470kb and corresponds to the small block we see in the genome view PDF.</p> <p>Quit out of viewing the segments file by pressing <code>q</code>.</p> <p>We will now open <code>IGV</code> and see if we can observe the predicted increase in copy number within these genomic coordinates.</p> <pre><code>/home/trainee/snv/Applications/igv/igv.sh\n</code></pre> <p>IGV will take 30 seconds or so to open so just be patient.</p> <p> For a duplication of this size, we will not be able to easily observe it just by looking at the raw read alignments. In order to see it we will generate two tiled data files (TDFs) within IGV which contain the average read depth for a given window size through the genome. This means that we can aggregate the average read depth over relatively large chunks of the genome and compare these values between the normal and tumour genomes.</p> <p>To begin, select the genome <code>Human (b37)</code>, go to <code>Tools</code> then <code>Run igvtools...</code> in the IGV menubar. Specify the normal bam file (under <code>cnv</code> then <code>data</code>) as the input file and change the window size to 100,000 (one hundred thousand). Then press the <code>Run</code> button and IGV will make the TDF file. This takes about 5 minutes. Repeat this for the tumour genome.</p> <p>After you have both TDF files, go to <code>File</code> and <code>Load from file...</code> in the menubar and select the BAM and TDF files to open. Once you have opened them, they will appear as tracks along with the BAM tracks we loaded initially. Navigate to the genomic coordinates of our event (5:21,051,700-21,522,065) by typing it in the coordinate box at the top. Mouse over the two blue tracks to get the average depth values for the 100,000 bp windows. What you should see is that the liverMets sample has 3-6X more coverage than the Blood sample for the four windows that cover this region.</p> <p>This may seem a bit underwhelming, after all, wasn\u2019t the increase of the region to a copy number of 4, i.e. we expect a doubling of reads in the tumour? To explain why we are only seeing such a small coverage increase, we need to turn to our good friend mathematics!</p> <p>Imagine we have two 30X genomes for the normal and tumour samples and the tumour is at 100% purity. If there is a copy number increase to 4 in the tumour from 2 in the normal, the duplicated segment should indeed have twice as many reads as the same segment in the normal genome. Now, lets imagine the tumour genome was only at a purity of 50% (i.e. it contains 50% normal cells and 50% tumour cells). Now, half of the duplicated \u201ctumour genome\u201d segment will be at a copy number of 2 and half will be at 4. What does this mean when we sequence them as a mixture? The resulting average copy number of the block will be . Now what if we only have 16% tumour cells in our \u201ctumour genome\u201d? This will be (0.84*2)+(0.16*4) = 2.32. You can see how sequencing a low cellularity tumour at a low depth makes it much harder to infer copy number variations!</p> <p>Returning to our genomes at hand, when we previously looked at the cellularity estimate of this tumour we saw it was 20% from the small block we ran or 16% from the whole genome. Thus, the read depth increase of just 3-6X (about 10-20% more reads) in this segment is not surprising. A low cellularity tumour greatly reduces our power to infer copy number events as relatively small changes in depth can occur by chance in the genome and these can be mis-identified as copy number changes. As well as this, it reduces our power for other analyses since we must also remember that a tumour can itself contain multiple clones which have to share just 16% of reads.</p> <p>It is possible to sequence through a low-cellularity sample when, for example, there is no way to take another sample (as is the case of most biopsies). \u201cSequencing through\u201d means to simply sequence the tumour at a much higher coverage, usually 90-120X. This will mean that there will be a net increase in reads supplying evidence for copy number events and variants and in aggregate these will still retain power to infer these events when using tools that look at the whole genome like Sequenza does.</p>"},{"location":"modules/cancer-module-cnv/cnv-tut/#references","title":"References","text":"<ol> <li>F. Favero, T. Joshi, A. M. Marquard, N. J. Birkbak, M. Krzystanek,     Q. Li, Z. Szallasi, and A. C. Eklund. \u201cSequenza: allele-specific     copy number and mutation profiles from tumor sequencing data\u201d.     Annals of Oncology, 2015, vol. 26, issue 1, 64-70.</li> </ol>"},{"location":"modules/cancer-module-qc/ngs-qc/","title":"Quality Control","text":""},{"location":"modules/cancer-module-qc/ngs-qc/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Assess the overall quality of NGS (FastQ format) sequence reads</p> </li> <li> <p>Visualise the quality, and other associated matrices, of reads to     decide on filters and cutoffs for cleaning up data ready for     downstream analysis</p> </li> <li> <p>Clean up adaptors and pre-process the sequence data for further     analysis</p> </li> </ul>"},{"location":"modules/cancer-module-qc/ngs-qc/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-qc/ngs-qc/#tools-used","title":"Tools Used","text":"<p>FastQC: http://www.bioinformatics.babraham.ac.uk/projects/fastqc/</p> <p>Skewer: http://sourceforge.net/projects/skewer/</p> <p>FASTX-Toolkit: http://hannonlab.cshl.edu/fastx_toolkit/</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#useful-links","title":"Useful Links","text":"<p>FASTQ Encoding: (http://en.wikipedia.org/wiki/FASTQ_format#Encoding)</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#author-information","title":"Author Information","text":"<p>Primary Author(s):  Sonika Tyagi: sonika.tyagi@monash.edu</p> <p>Contributor(s):  Nandan Deshpande: n.deshpande@unsw.edu.au</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#introduction","title":"Introduction","text":"<p>Going on a blind date with your read set? For a better understanding of the consequences please check the data quality!</p> <p>For the purpose of this tutorial we are focusing only on Illumina sequencing which uses \u2019sequence by synthesis\u2019 technology in a highly parallel fashion. Although Illumina high throughput sequencing provides highly accurate sequence data, several sequence artifacts, including base calling errors and small insertions/deletions, poor quality reads and primer/adapter contamination are quite common in the high throughput sequencing data. The primary errors are substitution errors. The error rates can vary from 0.5-2.0% with errors mainly rising in frequency at the 3\u2019 ends of reads.</p> <p>One way to investigate sequence data quality is to visualize the quality scores and other metrics in a compact manner to get an idea about the quality of a read data set. Read data sets can be improved by pre processing in different ways like trimming off low quality bases, cleaning up any sequencing adapters, removing PCR duplicates and screening for contamination. We can also look at other statistics such as, sequence length distribution, base composition, sequence complexity, presence of ambiguous bases etc. to assess the overall quality of the data set.</p> <p>Highly redundant coverage (&gt;15X) of the genome can be used to correct sequencing errors in the reads before assembly. Various k-mer based error correction methods exist but are beyond the scope of this tutorial.</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#quality-value-encoding-schema","title":"Quality Value Encoding Schema","text":"<p>Quality scoring calculates a set of predictors for each base call, and then uses the predictor values to look up the Q-score in a quality table. Quality tables are created to provide optimally accurate quality predictions for runs generated by a specific configuration of sequencing platform and version of chemistry (www.illumina.com). In order to use a single character to encode Phred qualities, ASCII characters are used. All ASCII characters have a decimal number associated with them but the first 32 characters are non-printable (e.g. backspace, shift, return, escape). Therefore, the first printable ASCII character is number 33, the exclamation mark (<code>!</code>). In Phred+33 encoded quality values the exclamation mark takes the Phred quality score of zero.</p> <p>Early Solexa (now Illumina) sequencing needed to encode negative quality values. Because ASCII characters &lt; 33 are non-printable, using the Phred+33 encoding was not possible. Therefore, they simply moved the offset from 33 to 64 thus inventing the Phred+64 encoded quality values. In this encoding a Phred quality of zero is denoted by the ASCII number 64 (the @ character). Since Illumina 1.8, quality values are now encoded using Phred+33.</p> <p>FASTQ does not provide a way to describe what quality encoding is used for the quality values. Therefore, you should find this out from your sequencing provider. Alternatively, you may be able to figure this out by determining what ASCII characters are present in the FASTQ file. E.g the presence of numbers in the quality strings, can only mean the quality values are Phred+33 encoded. However, due to the overlapping nature of the Phred+33 and Phred+64 encoding schema it is not always possible to identify what encoding is in use. For example, if the only characters seen in the quality string are (<code>@ABCDEFGHI</code>), then it is impossible to know if you have really good Phred+33 encoded qualities or really bad Phred+64 encoded qualities.</p> <p>For a graphical representation of the different ASCII characters used in the two encoding schema see: (http://en.wikipedia.org/wiki/FASTQ_format#Encoding).</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#q-score-encoding-implemented-with-the-novaseq-platform","title":"Q-score encoding implemented with the Novaseq platform","text":"<p>In order to reduce the data footprints Illumina has come up with a new method to reduce quality score resolution and optimise data storae. The new Q-score encoding now follows an 8 level mapping of individual quality scores (0-40 or &gt;40) [See Table 1]. With the new scoring scheme the original scores 20-24 may form one bin and the quality scores in that bin mapped to a new value of 22. This can be thought of as simply replacing all the occurrences of scores 20, 21, 23, 24 with a new score of 22 in the output sequence. Illumina claims that with the new Q-scoring system the reduction in the Illumina raw sequence format (.bcl) is typically &gt; 50% and the resulting sorted BAM  les are reduced by ~30%.</p>    Quality Score Bins Mapped quality scores     N (no call) N (no call)   2-9 6   10-19 15   20-24 22   25-29 27   30-34 33   35-39 37   &gt;=40 40    <p>Table 1: Novaseq Q-score bins mapping</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#prepare-the-environment","title":"Prepare the Environment","text":"<p>To investigate sequence data quality we will demonstrate tools called FastQC and Skewer. FastQC will process and present the reports in a visual manner. Based on the results, the sequence data can be processed using the Skewer. We will use one data set in this practical, which can be found in the QC directory on your desktop.</p> <p>Open the Terminal and go to the directory where the data are stored:</p> <pre><code>cd\nls\ncd qc\npwd\n</code></pre> <p>At any time, help can be displayed for FastQC using the following command:</p> <pre><code>fastqc -h\n</code></pre> <p>Look at SYNOPSIS (Usage) and options after typing <code>fastqc -h</code></p>"},{"location":"modules/cancer-module-qc/ngs-qc/#quality-visualisation","title":"Quality Visualisation","text":"<p>We have a file for a good quality and bad quality statistics. FastQC generates results in the form of a zipped and unzipped directory for each input file.</p> <p>Execute the following command on the two files:</p> <pre><code>fastqc -f fastq qcdemo_R1.fastq.gz\nfastqc -f fastq qcdemo_R2.fastq.gz\n</code></pre> <p>View the FastQC report file of the bad data using a web browser such as firefox. The <code>&amp;</code> sign puts the job in the background.</p> <pre><code>firefox qcdemo_R2_fastqc.html &amp;\n</code></pre> <p> The report file will have a Basic Statistics table and various graphs and tables for different quality statistics e.g.:</p>    Property Value     Filename qcdemo_R2.fastq.gz   File type Conventional base calls   Encoding Sanger / Illumina 1.9   Total Sequences 1000000   Filtered Sequences 0   Sequence length 150   %GC 37    <p>Table 2: Summary statistics for bad_example_untrimmed</p>  <p>Figure 1: bad_example_untrimmed_QC_plot</p> <p>A Phred quality score (or Q-score) expresses an error probability. In particular, it serves as a convenient and compact way to communicate very small error probabilities. The probability that base A is wrong (P(A)) is expressed by a quality score, Q(A), according to the relationship:</p> <p>  </p> <p>The relationship between the quality score and error probability is demonstrated with the following table:</p>    Quality score, Q(A) Error probability, P(A) Accuracy of base call     10 0.1 90%   20 0.01 99%   30 0.001 99.9%   40 0.0001 99.99%   50 0.00001 99.999%    <p>Table 3: Quality Error Probabilities</p>  <p>Question</p> <p>How many sequences were there in your file? What is the read length?</p>   Answer <p>1,000,000. read length=150bp</p>     <p>Question</p> <p>Does the quality score values vary throughout the read length?</p>   Hint <p>Look at the \u2019per base sequence quality plot\u2019</p>     Answer <p>Yes. Quality scores are dropping towards the end of the reads.</p>     <p>Question</p> <p>What is the quality score range you see?</p>   Answer <p>2-40</p>     <p>Question</p> <p>At around which position do the scores start falling below Q20 for the 25% quartile range (25%of reads below Q20)?</p>   Answer <p>Around 30 bp position</p>     <p>Question</p> <p>How can we trim the reads to filter out the low quality data?</p>   Answer <p>By trimming off the bases after a fixed position of the read or by trimming off bases based on the quality score.</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#good-quality-data","title":"Good Quality Data","text":"<p>View the FastQC report files <code>fastqc_report.html</code> to see examples of a good quality data and compare the quality plot with that of the <code>bad_example_fastqc</code>.</p> <pre><code>firefox qcdemo_R1_fastqc.html &amp;\n</code></pre> <p>Sequencing errors can complicate the downstream analysis, which normally requires that reads be aligned to each other (for genome assembly) or to a reference genome (for detection of mutations). Sequence reads containing errors may lead to ambiguous paths in the assembly or improper gaps. In variant analysis projects sequence reads are aligned against the reference genome. The errors in the reads may lead to more mismatches than expected from mutations alone. But if these errors can be removed or corrected, the read alignments and hence the variant detection will improve. The assemblies will also improve after pre-processing the reads to remove errors.</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#read-trimming","title":"Read Trimming","text":"<p>Read trimming can be done in a variety of different ways. Choose a method which best suits your data. Here we are giving examples of fixed-length trimming and quality-based trimming.</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#quality-based-trimming","title":"Quality Based Trimming","text":"<p>Base call quality scores can be used to dynamically determine the trim points for each read. A quality score threshold and minimum read length following trimming can be used to remove low quality data.</p> <p>The previous FastQC results show R1 is fine but R2 has low quality at the end. There is no adaptor contamination though. We will be using Skewer to perform the quality trimming.</p> <p>Run the following command to quality trim a set of paired end data.</p> <pre><code>cd /home/trainee/qc\nskewer -t 4 -l 50  -q 30 -Q 25 -m pe -o qcdemo qcdemo_R1.fastq.gz qcdemo_R2.fastq.gz\n</code></pre>  <p>-t: number of threads to use -l: min length to keep after trimming -q: Quality threshold used for trimming at 3\u2019 end -Q: mean quality threshold for a read -m: pair-end mode  </p>  <p> Run FastQC on the quality trimmed file and visualise the quality scores.</p> <p>Look at the last files generated, are the file names same as the input ?</p> <pre><code>ls -ltr\n</code></pre> <p>Run Fastqc on the quality trimmed files:</p> <pre><code>fastqc -f fastq qcdemo-trimmed-pair1.fastq\nfastqc -f fastq qcdemo-trimmed-pair2.fastq\n</code></pre> <p>Visualise the <code>fastqc</code> results:</p> <pre><code>firefox qcdemo-trimmed-pair1_fastqc.html &amp;\nfirefox qcdemo-trimmed-pair2_fastqc.html &amp;\n</code></pre> <p> Let\u2019s look at the quality from the second reads. The output should look like:</p>    Property Value     Filename qcdemo-trimmed-pair2.fastq   File type Conventional base calls   Encoding Sanger / Illumina 1.9   Total Sequences 742262   Filtered Sequences 0   Sequence length 50-150   %GC 37    <p>Table 4: Summary Statistics of QC_demo_R1_trimmed</p>  <p>Figure 2: bad_example_quality_trimmed_plot</p>  <p>Question</p> <p>Did the number of total reads in R1 and R2 change after trimming?</p>   Answer <p>Quality trimming discarded &gt;25000 reads. However, we retain a lot of maximal length reads which have good quality all the way to the ends.</p>     <p>Question</p> <p>What reads lengths were obtained after quality based trimming?</p>   Answer <p>50-150 Reads &lt;50 bp, following quality trimming, were discarded.</p>     <p>Question</p> <p>Did you observe adapter sequences in the data?</p>   Answer <p>No. (Hint: look at the overrepresented sequences)    </p>     <p>Question</p> <p>How can you use -a option with fastqc? (Hint: try fastqc -h).</p>   Answer <p>Adaptors can be supplied in a file for screening.</p>"},{"location":"modules/cancer-module-qc/ngs-qc/#adapter-clipping","title":"Adapter Clipping","text":"<p>Sometimes sequence reads may end up getting the leftover of adapters and primers used in the sequencing process. It\u2019s good practice to screen your data for these possible contamination for more sensitive alignment and assembly based analysis.</p> <p>This is particularly important when read lengths can be longer than the molecules being sequenced. For example when sequencing miRNAs.</p> <p>Various QC tools are available to screen and/or clip these adapter/primer sequences from your data. Apart from <code>skewer</code> which will be using today the following two tools are also useful for trimming and removing adapter sequence:</p> <ul> <li>Cutadapt: http://code.google.com/p/cutadapt/</li> <li>Trimmomatic: http://www.usadellab.org/cms/?page=trimmomatic</li> </ul> <p>Here we are demonstrating <code>Skewer</code> to trim a given adapter sequence.</p> <pre><code>cd /home/trainee/qc\nfastqc -f fastq  adaptorQC.fastq.gz\nfirefox adaptorQC_fastqc.html\nskewer -x TGGAATTCTCGGGTGCCAAGGT -t 20 -l 10 -L 35 -q 30 adaptorQC.fastq.gz\n</code></pre>  <p>-x: adaptor sequence used -t: number of threads to use -l: min length to keep after trimming -L: Max length to keep after trimming, in this experiment we were expecting only small RNA fragments -Q: Quality threshold used for trimming at 3\u2019 end. Use -m option to control the end you want to trim  </p>  <p> Run FastQC on the adapter trimmed file and visualise the quality scores. Fastqc now shows adaptor free results.</p> <pre><code>fastqc adaptorQC.fastq-trimmed.fastq\nfirefox adaptorQC.fastq-trimmed_fastqc.html &amp;\n</code></pre>"},{"location":"modules/cancer-module-qc/ngs-qc/#fixed-length-trimming","title":"Fixed Length Trimming","text":"<p>We will not cover fixed length trimming but provide the following for your information. Low quality read ends can be trimmed using a fixed-length trimming. We will use the <code>fastx_trimmer</code> from the FASTX-Toolkit. Usage message to find out various options you can use with this tool. Type <code>fastx_trimmer -h</code> at anytime to display help.</p> <p>We will now do fixed-length trimming of the <code>bad_example.fastq</code> file using the following command. You should still be in the qc directory, if not cd back in.</p> <pre><code>cd /home/trainee/qc\nfastqc -f fastq bad_example.fastq\nfastx_trimmer -h\nfastx_trimmer -Q 33 -f 1 -l 80 -i bad_example.fastq -o bad_example_trimmed01.fastq\n</code></pre> <p>We used the following options in the command above:</p>  <p>-Q 33: Indicates the input quality scores are Phred+33 encoded -f: First base to be retained in the output -l: Last base to be retained in the output -i: Input FASTQ file name -o: Output file name  </p>  <p> Run FastQC on the trimmed file and visualise the quality scores of the trimmed file.</p> <pre><code>fastqc -f fastq bad_example_trimmed01.fastq\nfirefox bad_example_trimmed01_fastqc.html &amp;\n</code></pre> <p>The output should look like:</p>    Property Value     Filename bad_example_trimmed01.fastq   File type Conventional base calls   Encoding Sanger / Illumina 1.9   Total Sequences 40000   Filtered Sequences 0   Sequence length 80   %GC 48    <p>Table 5: Summary Statistics of bad_example_trimmed summary</p>  <p>Figure 3: bad_example_trimmed_plot</p>  <p>Question</p> <p>What values would you use for <code>-f</code> if you wanted to trim off 10 bases at the 5\u2019 end of the reads?</p>   Answer <p><code>-f 11</code></p>"},{"location":"modules/cancer-module-snv/snv/","title":"Single Nucleotide Variant Calling and Annotation","text":""},{"location":"modules/cancer-module-snv/snv/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Prepare raw BAM alignments for variant detection</p> </li> <li> <p>Perform QC measures on BAM files</p> </li> <li> <p>Perform simple variant detection on paired NGS data</p> </li> <li> <p>Add annotation information to raw variant calls</p> </li> <li> <p>Visualise variant calls using IGV</p> </li> </ul>"},{"location":"modules/cancer-module-snv/snv/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-snv/snv/#tools-used","title":"Tools Used","text":"<p>SAMTools: https://samtools.github.io/</p> <p>IGV: http://www.broadinstitute.org/igv/</p> <p>Genome Analysis Toolkit: http://www.broadinstitute.org/gatk/</p> <p>Picard: https://broadinstitute.github.io/picard/</p> <p>MuTect: http://www.broadinstitute.org/cancer/cga/mutect/</p> <p>Strelka: https://sites.google.com/site/strelkasomaticvariantcaller/</p> <p>VarScan2: https://dkoboldt.github.io/varscan/</p> <p>Variant Effect Predictor: http://www.ensembl.org/info/docs/tools/vep</p> <p>GEMINI: http://gemini.readthedocs.org</p>"},{"location":"modules/cancer-module-snv/snv/#sources-of-data","title":"Sources of Data","text":"<p>http://sra.dnanexus.com/studies/ERP001071 http://www.ncbi.nlm.nih.gov/pubmed/22194472</p>"},{"location":"modules/cancer-module-snv/snv/#author-information","title":"Author Information","text":"<p>Primary Author(s): Matt Field matt.field@anu.edu.au Dan Andrews dan.andrews@anu.edu.au Velimir Gayevskiy v.gayevskiy@garvan.org.au Mathieu Bourgey mathieu.bourgey@mcgill.ca </p> <p>Contributor(s): Gayle Philip Sonika.Tyagi@agrf.org.au Sonika Tyagi gkphilip@unimelb.edu.au </p>"},{"location":"modules/cancer-module-snv/snv/#introduction","title":"Introduction","text":"<p>The goal of this hands-on session is to present the main steps that are commonly used to process and to analyze cancer sequencing data. We will focus only on whole genome data and provide command lines that allow detecting Single Nucleotide Variants (SNV). This workshop will show you how to launch individual steps of a complete DNA-Seq SNV pipeline using cancer data.</p> <p>In the second part of the tutorial we will also be using IGV to visualise and manually inspect candidate variant calls.</p>"},{"location":"modules/cancer-module-snv/snv/#prepare-the-environment","title":"Prepare the Environment","text":"<p>We will use a dataset derived from whole genome sequencing of a 33-yr-old lung adenocarcinoma patient, who is a never-smoker and has no familial cancer history.</p> <p>The data consists of whole genome sequencing of liver metastatic lung cancer (frozen), primary lung cancer (FFPE) and blood tissue of a lung adenocarcinoma patient (AK55).</p> <p>Open the Terminal and go to the <code>snv</code> working directory:</p> <pre><code>cd /home/trainee/snv/\n</code></pre>  <p>All commands entered into the terminal for this tutorial should be from within the <code>snv</code> directory.</p>  <p>The BAM alignment files are contained in the subdirectory called <code>alignment</code> and are located in the following subdirectories:</p>  <p><code>normal/normal.sorted.bam</code> and <code>normal/normal.sorted.bam.bai</code></p> <p><code>tumour/tumor.sorted.bam</code> and <code>tumour/tumour.sorted.bam.bai</code></p>  <p>Check that the <code>alignment</code> directory contains the above-mentioned files by typing:</p> <pre><code>ls -l alignment/*\n</code></pre> <p> These files are based on subsetting the whole genomes derived from blood and liver metastases to the first 10Mb of chromosome 4. This will allow our analyses to run in a sufficient time during the workshop, but it\u2019s worth being aware that this is less &lt; 0.5% of the genome which highlights the length of time and resources required to perform cancer genomics on full genomes!</p> <p>The initial structure of your folders should look like this (type <code>ls -l</code>):</p> <pre><code>-- alignment/             # bam files\n  -- normal/                # The blood sample directory containing bam files\n  -- tumour/                # The tumour sample directory containing bam files\n-- ref/                   # Contains reference genome files      \n</code></pre> <p> Now we need to set some environment variables to save typing lengthy file paths over and over. Copy and paste the following commands into your terminal.</p> <pre><code>export APP_ROOT=/home/trainee/snv/Applications\nexport IGVTOOLS_PATH=$APP_ROOT/igvtools/\nexport PICARD_JAR=$APP_ROOT/picard/picard.jar\nexport GATK_JAR=$APP_ROOT/gatk/GenomeAnalysisTK.jar\nexport STRELKA_HOME=$APP_ROOT/strelka/\nexport MUTECT_JAR=$APP_ROOT/mutect/muTect-1.1.5.jar\nexport VARSCAN_JAR=$APP_ROOT/varscan/VarScan.v2.4.1.jar\nexport REF=/home/trainee/snv/ref\nexport SNV_BASE=/home/trainee/snv\nexport JAVA7=/usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java\nexport IGV=$APP_ROOT/igv/igv.sh\nexport VEP=$APP_ROOT/ensembl-tools/scripts/variant_effect_predictor/variant_effect_predictor.pl\nexport VEP_CACHE=/mnt/workshop/data/bgdata/datasets/vepcache/82\n</code></pre> <p> Make sure you are in the correct directory by typing:</p> <pre><code>cd $SNV_BASE\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#bam-files","title":"BAM Files","text":"<p>Let\u2019s spend some time exploring BAM files.</p>"},{"location":"modules/cancer-module-snv/snv/#exploring-bam-files","title":"Exploring BAM files","text":"<pre><code>samtools view alignment/normal/normal.sorted.bam | head -n4\n</code></pre> <p>Here you have examples of alignment results. A full description of the flags can be found in the SAM specification.</p> <p>Another useful bit of information in the SAM is the CIGAR string. It\u2019s the 6th column in the file.</p> <p>This column explains how the alignment was achieved.</p>  <p>M == base aligns but doesn\u2019t have to be a match. A SNP will have an M even if it disagrees with the reference. I == Insertion D == Deletion S == soft-clips. These are handy to find un removed adapters, viral insertions, etc.</p>  <p>An in-depth explanation of the CIGAR can be found here. The exact details of the CIGAR string can be found in the SAM specification as well. We won\u2019t go into too much detail at this point since we want to concentrate on cancer specific issues now.</p> <p>Now, you can try using Picard\u2019s explain flag site to understand what is going on with your reads.</p>  <p>Question</p> <p>There are 3 unique flags, what do they mean? The flag is the second column.</p>   Answer <p>129: read paired second in pair  </p> <p>113: read paired read reverse strand mate reverse strand first in pair  </p> <p>161: read paired mate reverse strand second in pair  </p>    <p> There are lots of possible different flags, let\u2019s look at a few more</p> <pre><code>samtools view alignment/normal/normal.sorted.bam | head -n 100\n</code></pre>  <p>Question</p> <p>Let\u2019s take the last read, which looks properly paired and find its mate pair.</p>   Hint <p>a)    Instead of using <code>head</code>, what unix command could we pipe the output to? b)    Once we\u2019ve found both reads, the command can be stopped by typing <code>CTRL-C</code> </p>     Answer <pre><code>samtools view alignment/normal/normal.sorted.bam | grep HWI-ST478_0133:4:2205:14675:32513\n</code></pre>     <p>Question</p> <p>Using the cigar string, what can we tell about the alignment of the mate pair?</p>   Answer <p>The mate pair has a less convincing alignment with two insertions and soft clipping reported.</p>     <p>Question</p> <p>How might the alignment information from the original read be used by the aligner?</p>   Answer <p>Even though the alignment of the mate pair is questionable the presence   of it\u2019s properly paired mate helps the aligner in deciding where to put   the less-certain read.</p>    <p>You can use <code>Samtools</code> to filter reads as well.</p>  <p>Question</p> <p>How many reads mapped and unmapped were there?</p>   Hint <p>Look at the samtools view help menu by typing <code>samtools view</code> without any arguments</p>     Answer <p><pre><code>samtools view -c -f4 alignment/normal/normal.sorted.bam\n</code></pre> 77229 <pre><code>samtools view -c -F4 alignment/normal/normal.sorted.bam\n</code></pre> 22972373</p>"},{"location":"modules/cancer-module-snv/snv/#step-1-pre-processing-indel-realignment","title":"Step 1: Pre-processing: Indel Realignment","text":"<p>The first step for this is to realign around indels and SNP dense regions. The Genome Analysis toolkit (<code>GATK</code>) has a tool for this called IndelRealigner. It basically runs in 2 steps:  </p> <ol> <li>Find the targets</li> <li>Realign them</li> </ol> <pre><code>$JAVA7 -Xmx2G  -jar ${GATK_JAR} \\\n  -T RealignerTargetCreator \\\n  -R ${REF}/human_g1k_v37.fasta \\\n  -o alignment/normal/realign.intervals \\\n  -I alignment/normal/normal.sorted.bam \\\n  -I alignment/tumour/tumour.sorted.bam \\\n  -L ${REF}/human_g1k_v37.intervals\n</code></pre> <pre><code>$JAVA7 -Xmx2G -jar ${GATK_JAR} \\\n  -T IndelRealigner \\\n  -R ${REF}/human_g1k_v37.fasta \\\n  -targetIntervals alignment/normal/realign.intervals \\\n  --nWayOut .realigned.bam \\\n  -I alignment/normal/normal.sorted.bam \\\n  -I alignment/tumour/tumour.sorted.bam \\\n  -L ${REF}/human_g1k_v37.intervals\n</code></pre> <p>Explanation of parameters:</p>  <p>-I: BAM file(s) -T: GATK algorithm to run -R: the reference genome used for mapping (b37 from GATK here) -jar: Path to GATK jar file -L: Genomic intervals to operate on</p>  <p> Move the realigned BAMs and index files to the corresponding normal and tumour directories.</p> <pre><code>mv normal.sorted.realigned.ba* alignment/normal/\nmv tumour.sorted.realigned.ba* alignment/tumour/\n</code></pre>  <p>Question</p> <p>Why did we use both normal and tumor together?</p>   Answer <p>Because if a region needs realignment, maybe one of the samples in the pair has less reads or was excluded from the target creation. This makes sure the normal and tumor are all in-sync for the somatic calling step.</p>     <p>Question</p> <p>How many regions did it think needed cleaning?</p>   Answer <pre><code>wc -l alignment/normal/realign.intervals\n</code></pre> <p>27300</p>    <p> Indel Realigner also makes sure the called deletions are left aligned when there is a microsatellite or homopolymer. e.g.</p> <p>This   ATCGAAAA-TCG   into   ATCG-AAAATCG  </p> <p>or  </p> <p>ATCGATATATATA\u2013TCG   into   ATCG\u2013ATATATATATCG  </p>   <p>Question</p> <p>Why is it important?</p>   Answer <p>This makes it easier for downstream analysis tools.</p> <p>For NGS analysis, the convention is to left align indels.</p> <p>This is only really needed when calling variants with legacy locus-based tools such as samtools or GATK UnifiedGenotyper. Otherwise you will have worse performance and accuracy.</p> <p>With more sophisticated tools (like GATK HaplotypeCaller) that involve reconstructing haplotypes (e.g. through reassembly), the problem of multiple valid representations is handled internally and does not need to be corrected explicitly.</p>"},{"location":"modules/cancer-module-snv/snv/#step-2-pre-processing-fixmates","title":"Step 2: Pre-processing: Fixmates","text":"<p>Some read entries don\u2019t have their mate information written properly. We use <code>Picard</code> to do this:</p> <p>Normal sample:   <pre><code>$JAVA7 -Xmx2G -jar ${PICARD_JAR} FixMateInformation \\\n  VALIDATION_STRINGENCY=SILENT \\\n  CREATE_INDEX=true \\\n  SORT_ORDER=coordinate \\\n  MAX_RECORDS_IN_RAM=500000 \\\n  INPUT=alignment/normal/normal.sorted.realigned.bam \\\n  OUTPUT=alignment/normal/normal.matefixed.bam\n</code></pre></p> <p>Tumour sample:  <pre><code>$JAVA7 -Xmx2G -jar ${PICARD_JAR} FixMateInformation \\\n  VALIDATION_STRINGENCY=SILENT \\\n  CREATE_INDEX=true \\\n  SORT_ORDER=coordinate \\\n  MAX_RECORDS_IN_RAM=500000 \\\n  INPUT=alignment/tumour/tumour.sorted.realigned.bam \\\n  OUTPUT=alignment/tumour/tumour.matefixed.bam\n</code></pre></p>"},{"location":"modules/cancer-module-snv/snv/#step-3-pre-processing-mark-duplicates","title":"Step 3: Pre-processing: Mark Duplicates","text":"<p>Question</p> <p>What are duplicate reads?</p>   Answer <p>Different read pairs representing the same initial DNA fragment.</p>     <p>Question</p> <p>What are they caused by?</p>   Answer <ul> <li>PCR reactions (PCR duplicates).  </li> <li>Some clusters that are thought of being separate in the flowcell but are the same (optical duplicates)</li> </ul>     <p>Question</p> <p>What are the ways to detect them?</p>   Answer <ol> <li> <p>Picard and samtools uses the alignment positions:  </p> <ul> <li>Both 5\u2019 ends of both reads need to have the same positions.</li> <li>Each reads have to be on the same strand as well.</li> </ul> </li> <li> <p>Another method is to use a kmer approach:</p> <ul> <li>Take a part of both ends of the fragment.</li> <li>Build a hash table.</li> <li>Count the similar hits.</li> </ul> </li> <li> <p>Brute force, compare all the sequences.</p> </li> </ol>    <p> Here we will use <code>Picard</code>\u2018s approach:</p> <p>Normal Sample:   <pre><code>$JAVA7 -Xmx2G -jar ${PICARD_JAR} MarkDuplicates \\\n  REMOVE_DUPLICATES=false \\\n  CREATE_MD5_FILE=true \\\n  VALIDATION_STRINGENCY=SILENT \\\n  CREATE_INDEX=true \\\n  INPUT=alignment/normal/normal.matefixed.bam \\\n  OUTPUT=alignment/normal/normal.sorted.dup.bam \\\n  METRICS_FILE=alignment/normal/normal.sorted.dup.metrics\n</code></pre></p> <p>Tumour Sample: <pre><code>$JAVA7 -Xmx2G -jar ${PICARD_JAR} MarkDuplicates \\\n  REMOVE_DUPLICATES=false \\\n  CREATE_MD5_FILE=true \\\n  VALIDATION_STRINGENCY=SILENT \\\n  CREATE_INDEX=true \\\n  INPUT=alignment/tumour/tumour.matefixed.bam \\\n  OUTPUT=alignment/tumour/tumour.sorted.dup.bam \\\n  METRICS_FILE=alignment/tumour/tumour.sorted.dup.metrics\n</code></pre></p> <p> We can look in the metrics output to see what happened.</p> <pre><code>less alignment/normal/normal.sorted.dup.metrics\n</code></pre>  <p>Question</p> <p>What percent of reads are duplicates?</p>   Answer <p>0.046996%</p>     <p>Question</p> <p>Often, we have multiple libraries and when this occurs separate measures are calculated for each library. Why is it important to not combine everything?</p>   Answer <ul> <li>Each library represents a set of different DNA fragments.</li> <li>Each library involves different PCR reactions</li> </ul> <p>PCR duplicates can not occur between fragments of two different libraries. However, similar fragments could be found between libraries when the coverage is high.</p>"},{"location":"modules/cancer-module-snv/snv/#step-4-pre-processing-base-quality-recalibration","title":"Step 4: Pre-processing: Base Quality Recalibration","text":"<p>Question</p> <p>Why do we need to recalibrate base quality scores?</p>   Answer <p>The vendors tend to inflate the values of the bases in the reads. The recalibration tries to lower the scores of some biased motifs for some technologies.</p>    <p> Base Quality Recalibration runs in 2 steps:</p> <ol> <li>Build covariates based on context and known SNP sites.</li> <li>Correct the reads based on these metrics.</li> </ol> <p>GATK BaseRecalibrator:</p> <pre><code>for i in normal tumour\ndo\n  $JAVA7 -Xmx2G -jar ${GATK_JAR} \\\n    -T BaseRecalibrator \\\n    -nct 2 \\\n    -R ${REF}/human_g1k_v37.fasta \\\n    -knownSites ${REF}/dbSnp-138_chr4.vcf \\\n    -L 4:1-10000000 \\\n    -o alignment/${i}/${i}.sorted.dup.recalibration_report.grp \\\n    -I alignment/${i}/${i}.sorted.dup.bam\n\n    $JAVA7 -Xmx2G -jar ${GATK_JAR} \\\n      -T PrintReads \\\n      -nct 2 \\\n      -R ${REF}/human_g1k_v37.fasta \\\n      -BQSR alignment/${i}/${i}.sorted.dup.recalibration_report.grp \\\n      -o alignment/${i}/${i}.sorted.dup.recal.bam \\\n      -I alignment/${i}/${i}.sorted.dup.bam\ndone\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#bam-qc","title":"BAM QC","text":"<p>Once your whole BAM is generated, it\u2019s always a good thing to check the data again to see if everything makes sense.</p>"},{"location":"modules/cancer-module-snv/snv/#step-1-bam-qc-compute-coverage","title":"Step 1: BAM QC: Compute Coverage","text":"<p>If you have data from a capture kit, you should see how well your targets worked. <code>GATK</code> has a depth of coverage tool to do this:</p> <pre><code>for i in normal tumour\ndo\n  $JAVA7  -Xmx2G -jar ${GATK_JAR} \\\n    -T DepthOfCoverage \\\n    --omitDepthOutputAtEachBase \\\n    --summaryCoverageThreshold 10 \\\n    --summaryCoverageThreshold 25 \\\n    --summaryCoverageThreshold 50 \\\n    --summaryCoverageThreshold 100 \\\n    --start 1 --stop 500 --nBins 499 -dt NONE \\\n    -R ${REF}/human_g1k_v37.fasta \\\n    -o alignment/${i}/${i}.sorted.dup.recal.coverage \\\n    -I alignment/${i}/${i}.sorted.dup.recal.bam \\\n    -L 4:1-10000000\ndone\n</code></pre> <p>Explanation of parameters:</p>  <p>--omitBaseOutputAtEachBase: Do not output depth of coverage at each base --summaryCoverageThreshold: Coverage threshold (in percent) for summarizing statistics -dt: Downsampling -L: Genomic intervals to operate on  </p>  <p> In this project, coverage is expected to be 25x. Look at the coverage:</p> <pre><code>less -S alignment/normal/normal.sorted.dup.recal.coverage.sample_interval_summary\n</code></pre> <p>Type <code>q</code> to return to the prompt.</p> <pre><code>less -S alignment/tumour/tumour.sorted.dup.recal.coverage.sample_interval_summary\n</code></pre>  <p>Question</p> <p>Does the coverage fit with the expectation?</p>   Answer <ul> <li> <p>Yes the mean coverage of the region is 25x.</p> </li> <li> <p><code>summaryCoverageThreshold</code> is a useful function to see if your coverage is uniform.</p> </li> <li> <p>Another way is to compare the mean to the median. If both are quite different that means something is wrong in your coverage.</p> </li> </ul>"},{"location":"modules/cancer-module-snv/snv/#step-2-bam-qc-insert-size","title":"Step 2: BAM QC: Insert Size","text":"<p>Insert size corresponds to the size of DNA fragments sequenced. It is different from the gap size (= distance between reads)!</p> <p> These metrics are computed using <code>Picard</code>:</p> <pre><code>for i in normal tumour\ndo\n  $JAVA7 -Xmx2G -jar ${PICARD_JAR} CollectInsertSizeMetrics \\\n    VALIDATION_STRINGENCY=SILENT \\\n    REFERENCE_SEQUENCE=${REF}/human_g1k_v37.fasta \\\n    INPUT=alignment/${i}/${i}.sorted.dup.recal.bam \\\n    OUTPUT=alignment/${i}/${i}.sorted.dup.recal.metric.insertSize.tsv \\\n    HISTOGRAM_FILE=alignment/${i}/${i}.sorted.dup.recal.metric.insertSize.histo.pdf \\\n    METRIC_ACCUMULATION_LEVEL=LIBRARY\ndone\n</code></pre> <p> Look at the output:</p> <pre><code>less -S alignment/normal/normal.sorted.dup.recal.metric.insertSize.tsv\nless -S alignment/tumour/tumour.sorted.dup.recal.metric.insertSize.tsv\n</code></pre>  <p>Question</p> <p>How do the two libraries compare?    </p>   Answer <p>The tumour sample has a larger median insert size than the normal sample (405 vs. 329).</p>"},{"location":"modules/cancer-module-snv/snv/#step-3-bam-qc-alignment-metrics","title":"Step 3: BAM QC: Alignment metrics","text":"<p>Alignment metrics tells you if your sample and your reference fit together.</p> <p>For the alignment metrics, <code>samtools flagstat</code> is very fast but <code>bwa-mem</code> breaks some reads into pieces, the numbers can be a bit confusing.</p> <p>Instead, we will use <code>Picard</code> to compute the metrics:</p> <pre><code>for i in normal tumour\ndo\n  $JAVA7 -Xmx2G -jar ${PICARD_JAR} CollectAlignmentSummaryMetrics \\\n    VALIDATION_STRINGENCY=SILENT \\\n    REFERENCE_SEQUENCE=${REF}/human_g1k_v37.fasta \\\n    INPUT=alignment/${i}/${i}.sorted.dup.recal.bam \\\n    OUTPUT=alignment/${i}/${i}.sorted.dup.recal.metric.alignment.tsv \\\n    METRIC_ACCUMULATION_LEVEL=LIBRARY\ndone\n</code></pre> <p> Explore the results</p> <pre><code>less -S alignment/normal/normal.sorted.dup.recal.metric.alignment.tsv\nless -S alignment/tumour/tumour.sorted.dup.recal.metric.alignment.tsv\n</code></pre>  <p>Question</p> <p>Do you think the sample and the reference genome fit together?</p>   Answer <p>Yes, 99% of the reads have been aligned. Usually, we consider:</p> <ul> <li>A good alignment if &gt; 85%</li> <li>Reference assembly issues if [60-85]%</li> <li>Probably a mismatch between sample and ref if &lt; 60 %</li> </ul>"},{"location":"modules/cancer-module-snv/snv/#variant-calling","title":"Variant Calling","text":"<p>Most of SNV caller use either a Bayesian, a threshold or a t-test approach to do the calling</p> <p>Here we will try 3 variant callers:</p> <ul> <li><code>Varscan 2</code></li> <li><code>MuTecT</code></li> <li><code>Strelka</code></li> </ul> <p>Other candidates:</p> <ul> <li><code>Virmid</code></li> <li><code>Somatic sniper</code></li> </ul> <p>Many, MANY others can be found here: https://www.biostars.org/p/19104/</p> <p>In our case, let\u2019s create a new work directory to start with (from base directory):</p> <pre><code>cd $SNV_BASE\nmkdir variant_calling\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#varscan-2","title":"Varscan 2","text":"<p><code>Varscan 2</code> calls somatic variants (SNPs and indels) using a heuristic method and a statistical test based on the number of aligned reads supporting each allele. It expects both a normal and a tumour file in <code>SAMtools pileup</code> format from sequence alignments in binary alignment/map (BAM) format. To build a pileup file, you will need:</p> <ul> <li>A SAM/BAM file (<code>*.sorted.dup.recal.bam</code>) that has been sorted using the <code>sort</code> command of <code>samtools</code>.</li> <li>The reference sequence (<code>human_g1k_v37.fasta</code>) to which reads were aligned, in FASTA format.</li> <li>The <code>samtools</code> software package.</li> </ul> <pre><code>for i in normal tumour\ndo\nsamtools mpileup -L 1000 -B -q 1 \\\n  -f ${REF}/human_g1k_v37.fasta \\\n  -r 4:1-10000000 \\\n  alignment/${i}/${i}.sorted.dup.recal.bam \\\n  &gt; variant_calling/${i}.mpileup\ndone\n</code></pre> <p>Notes on <code>samtools</code> arguments:</p>  <p>-L: max per-sample depth for INDEL calling [1000] -B: disable BAQ (per-Base Alignment Quality) -q: skip alignments with mapQ smaller than 1 -g: generate genotype likelihoods in BCF format</p>  <p> <pre><code>$JAVA7 -Xmx2G -jar ${VARSCAN_JAR} \\\nsomatic variant_calling/normal.mpileup \\\nvariant_calling/tumour.mpileup \\\nvariant_calling/varscan \\\n--output-vcf 1 \\\n--strand-filter 1 \\\n--somatic-p-value 0.001\n</code></pre></p>"},{"location":"modules/cancer-module-snv/snv/#mutect","title":"MuTect","text":"<p>Now let\u2019s try a different variant caller, <code>MuTect</code>.</p> <pre><code>$JAVA7 -Xmx2G -jar ${MUTECT_JAR} \\\n  -T MuTect \\\n  -R ${REF}/human_g1k_v37.fasta \\\n  -dt NONE -baq OFF --validation_strictness LENIENT \\\n  --dbsnp ${REF}/dbSnp-138_chr4.vcf \\\n  --input_file:normal alignment/normal/normal.sorted.dup.recal.bam \\\n  --input_file:tumor alignment/tumour/tumour.sorted.dup.recal.bam \\\n  --out variant_calling/mutect.call_stats.txt \\\n  --coverage_file variant_calling/mutect.wig.txt \\\n  -pow variant_calling/mutect.power \\\n  -vcf variant_calling/mutect.vcf \\\n  -L 4:1-10000000\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#strelka","title":"Strelka","text":"<p>And finally let\u2019s try Illumina\u2019s <code>Strelka</code>.</p> <pre><code>cp ${STRELKA_HOME}/etc/strelka_config_bwa_default.ini .\n\nsed 's/isSkipDepthFilters =.*/isSkipDepthFilters = 1/g' -i strelka_config_bwa_default.ini\n\n${STRELKA_HOME}/bin/configureStrelkaWorkflow.pl \\\n  --normal=alignment/normal/normal.sorted.dup.recal.bam \\\n  --tumor=alignment/tumour/tumour.sorted.dup.recal.bam \\\n  --ref=${REF}/human_g1k_v37.fasta \\\n  --config=${SNV_BASE}/strelka_config_bwa_default.ini \\\n  --output-dir=variant_calling/strelka/\n\ncd variant_calling/strelka/\nmake -j2\ncd ../..\n\ncp variant_calling/strelka/results/passed.somatic.snvs.vcf variant_calling/strelka.vcf\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#comparing-variant-callers","title":"Comparing variant callers","text":"<p>Now we have variants from all three methods. Let\u2019s compress and index the VCFs for future visualisation.</p> <pre><code>for i in variant_calling/*.vcf; do bgzip -c $i &gt; $i.gz ; tabix -p vcf $i.gz; done\n</code></pre> <p>Let\u2019s look at a compressed VCF. Details on the VCF spec can be found here.</p> <pre><code>zless -S variant_calling/varscan.snp.vcf.gz\n</code></pre> <p> Fields vary from caller to caller. Some values are are almost always there:</p> <ul> <li>Ref vs. alt alleles</li> <li>Variant quality (QUAL column)</li> <li>The per-sample genotype (GT) values.</li> </ul> <p>Note on VCF fields:</p>  <p>DP: Raw read depth GT: Genotype PL: List of Phred-scaled genotype likelihoods. (min is better) DP: \u201c\u201d# high-quality bases\u201d SP: Phred-scaled strand bias P-value GQ: Genotype Quality  </p>    <p>Question</p> <p>Looking at the three vcf files, how can we detect only somatic variants?</p>   Answer <p>Some commands to find somatic variant in the vcf file:</p> <p>varscan:</p> <pre><code>grep SOMATIC variant_calling/varscan.snp.vcf\n</code></pre> <p>MuTecT:</p> <pre><code>grep -v REJECT variant_calling/mutect.vcf | grep -v \"^#\"\n</code></pre> <p>Strelka:</p> <pre><code>grep -v \"^#\" variant_calling/strelka.vcf\n</code></pre>"},{"location":"modules/cancer-module-snv/snv/#variant-visualisation","title":"Variant Visualisation","text":"<p>The Integrative Genomics Viewer (<code>IGV</code>) is an efficient visualization tool for interactive exploration of large genome datasets.</p> <p>Before jumping into <code>IGV</code>, we\u2019ll generate a track IGV that can be used to plot coverage:</p> <pre><code>for i in normal tumour\ndo\n  $JAVA7 -jar ${IGVTOOLS_PATH}/igvtools.jar count \\\n    -f min,max,mean \\\n    alignment/${i}/${i}.sorted.dup.recal.bam \\\n    alignment/${i}/${i}.sorted.dup.recal.bam.tdf \\\n    b37\ndone\n</code></pre> <p>Open <code>IGV</code></p> <pre><code>$IGV\n</code></pre> <p>Then:</p> <ol> <li>Choose the reference genome corresponding to those use for alignment (b37).</li> <li>Load BAM files from the <code>alignment</code> folder (<code>tumour.sorted.dup.recal.bam</code> and <code>normal.sorted.dup.recal.bam</code>).</li> <li>Load three VCF files (from <code>variant_calling</code> directory).</li> </ol>  <p>Explore and play with the data:</p> <ul> <li>Find germline variants</li> <li>Find somatic variants</li> <li>Look around\u2026</li> </ul>"},{"location":"modules/cancer-module-snv/snv/#variant-annotation","title":"Variant Annotation","text":"<p>Following variant calling, we end up with a VCF file of genomic coordinates with the genotype(s) and quality information for each variant. By itself, this information is not much use to us unless there is a specific genomic location we are interested in. Generally, we next want to annotate these variants to determine whether they impact any genes and if so what is their level of impact (e.g. are they causing a premature stop codon gain or are they likely less harmful missense mutations).</p> <p>The sections above have dealt with calling somatic variants from the first 10Mb of chromosome 4. This is important in finding variants that are unique to the tumour sample(s) and may have driven both tumour growth and/or metastasis. An important secondary question is whether the germline genome of the patient contains any variants that may have contributed to the development of the initial tumour through predisposing the patient to cancer. These variants may not be captured by somatic variant analysis as their allele frequency may not change in the tumour genome compared with the normal.</p> <p>For this section, we will use all variants from the first 60Mb of chromosome 5 that have been pre-generated using the GATK <code>HaplotypeCaller</code> variant caller on both the normal and tumour genomes. The output of this was GVCF files which were fed into GATK <code>GenotypeGVCFs</code> to produce a merged VCF file. We will use this pre-generated file as we are primarily interested in the annotation of variants rather than their generation. The annotation method we will use is called <code>Variant Effect Predictor</code> or <code>VEP</code> for short and is available from Ensembl here.</p> <p> Our pre-generated VCF file is located in the <code>variants</code> folder. Let\u2019s have a quick look at the variants:</p> <pre><code>zless variants/HC.chr5.60Mb.vcf.gz\n</code></pre> <p>Notice how there are two genotype blocks at the end of each line for the normal (<code>Blood</code>) and tumour (<code>liverMets</code>) samples.</p> <p> Let\u2019s now run <code>VEP</code> on this VCF file to annotate each variant with its impact(s) on the genome.</p> <pre><code>perl $VEP --dir_cache $VEP_CACHE -i variants/HC.chr5.60Mb.vcf.gz --vcf -o variants/HC.chr5.60Mb.vep.vcf --stats_file variants/HC.chr5.60Mb.vep.html --format vcf --offline -fork 4 --fasta ref/human_g1k_v37.fasta --fields Consequence,Codons,Amino_acids,Gene,SYMBOL,Feature,EXON,PolyPhen,SIFT,Protein_position,BIOTYPE --species homo_sapiens\n</code></pre> <p> <code>VEP</code> will take approximately 10 minutes to run and once it is finished you will have a new VCF file with all of the information in the input file but with added annotations in the INFO block. <code>VEP</code> also produces an HTML report summarising the distribution and impact of variants identified.</p> <p>Once <code>VEP</code> is done running, let\u2019s first look at the HTML report it produced with the following command:</p> <pre><code>firefox variants/HC.chr5.60Mb.vep.html\n</code></pre> <p>This report shows information on the <code>VEP</code> run, the number of variants, the classes of variants detected, the variant consequences and the distributions of variants through the genome. Close Firefox to resume the terminal prompt.</p> <p> Now let\u2019s look at the variant annotations that <code>VEP</code> has added to the VCF file by focussing on a single variant. Let\u2019s fetch the same variant from the original VCF file and the annotated VCF file to see what has been changed.</p> <pre><code>zcat variants/HC.chr5.60Mb.vcf.gz | grep '5\\s174106\\s'\ngrep '5\\s174106\\s' variants/HC.chr5.60Mb.vep.vcf\n</code></pre> <p> These commands give us the original variant:</p> <pre><code>5   174106  .   G   A   225.44  .   AC=2;AF=0.500;AN=4;BaseQRankSum=1.22;ClippingRankSum=0.811;DP=21;FS=0.000;GQ_MEAN=127.00;GQ_STDDEV=62.23;MLEAC=2;MLEAF=0.500;MQ=60.00;MQ0=0;MQRankSum=0.322;NCC=0;QD=10.74;ReadPosRankSum=0.377;SOR=0.446   GT:AD:DP:GQ:PL  0/1:7,6:13:99:171,0,208 0/1:5,3:8:83:83,0,145\n</code></pre> <p>and the same variant annotated is:</p> <pre><code>5   174106  .   G   A   225.44  .   AC=2;AF=0.500;AN=4;BaseQRankSum=1.22;ClippingRankSum=0.811;DP=21;FS=0.000;GQ_MEAN=127.00;GQ_STDDEV=62.23;MLEAC=2;MLEAF=0.500;MQ=60.00;MQ0=0;MQRankSum=0.322;NCC=0;QD=10.74;ReadPosRankSum=0.377;SOR=0.446;CSQ=missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|||1076|protein_coding,non_coding_transcript_exon_variant&amp;non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron  GT:AD:DP:GQ:PL  0/1:7,6:13:99:171,0,208 0/1:5,3:8:83:83,0,145\n</code></pre> <p> You can see that <code>VEP</code> has added:</p> <pre><code>CSQ=missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|||1076|protein_coding,non_coding_transcript_exon_variant&amp;non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron\n</code></pre> <p> This is further composed of two annotations for this variant: <pre><code>missense_variant|cGg/cAg|R/Q|ENSG00000153404|PLEKHG4B|ENST00000283426|16/18|||1076|protein_coding\n</code></pre></p> <p>and</p> <pre><code>non_coding_transcript_exon_variant&amp;non_coding_transcript_variant|||ENSG00000153404|PLEKHG4B|ENST00000504041|5/8||||retained_intron\n</code></pre> <p> The first of these is saying that this variant is a missense variant in the gene PLEKHG4B for the transcript ENST00000283426 and the second that it is also a non_coding_transcript_exon_variant in the transcript ENST00000504041.</p>"},{"location":"modules/cancer-module-snv/snv/#variant-filtration","title":"Variant Filtration","text":"<p>We now have a VCF file where each variant has been annotated with one or more impacts for one or more genes. In a typical whole cancer genome, you will have about 4-5 million variants, and therefore rows, in a VCF file which takes up gigabytes of space. In our small example, we have just 100,000 variants which is already too large to make any kind of meaningful sense out of by just opening up the VCF file in a text editor. We need a solution that allows us to perform intelligent queries on our variants to search this mass of noise for the signal we are interested in.</p> <p>Luckily, such a free tool exists and is called <code>GEMINI</code>. <code>GEMINI</code> takes as an input your annotated VCF file and creates a database file which it can then query using Structured Query Language (SQL) commands. Not only does <code>GEMINI</code> make your variants easily searchable, it also brings in many external annotations to add more information about your variants (such as their frequencies in international databases).</p> <p>To get started with <code>GEMINI</code>, let\u2019s make a database out of our annotated VCF file.</p> <pre><code>/usr/local/bin/gemini load -v variants/HC.chr5.60Mb.vep.vcf --cores 4 --skip-gerp-bp --skip-cadd -t VEP variants/HC.chr5.60Mb.vep.vcf.db\n</code></pre> <p>This will take approximately 10 minutes. You will see a few errors due to multiallelic sites, normally these sites are decomposed and normalized before creating the <code>GEMINI</code> database but this is outside the scope of this workshop.</p> <p>Once the database has been created let\u2019s run a basic query to see what kind of information we get out of <code>GEMINI</code>.</p> <pre><code>/usr/local/bin/gemini query -q \"SELECT *, (gts).(*), (gt_types).(*), (gt_depths).(*), (gt_ref_depths).(*), (gt_alt_depths).(*), (gt_quals).(*) FROM variants LIMIT 10;\" --header variants/HC.chr5.60Mb.vep.vcf.db\n</code></pre> <p>This will output a bunch of ordered information for your query to the command line, this is usually saved to a TSV file and opened in a spreadsheet as we will do for the next query. In the mean time, let\u2019s dissect this query to understand the syntax we need to use to filter our variants. First, we have a SELECT statement which simply specifies that we want to select data from the database. The following comma-separated values are the columns that we want to output from the database, in this case we are selecting all columns with the star character and then all sub-columns for each sample with the other values. Then, we have a \u201cFROM variants\u201d statement which is specifying the table within the database that we want to fetch information from. Finally, the \u201cLIMIT 10\u201d statement specifies that no more than 10 rows should be returned. In summary then, we are asking for all columns for 10 rows from the table <code>variants</code>. If you haven\u2019t used SQL before don\u2019t worry, the <code>GEMINI</code> website is very helpful and provides many examples for how to query your database.</p> <p>Let\u2019s now perform a more interesting query to find variants that have a medium or high impact on a gene and are rare or not present in existing international allele frequency databases. We will save the output of this query to a file and open it up in a spreadsheet.</p> <pre><code>/usr/local/bin/gemini query -q \"SELECT *, (gts).(*), (gt_types).(*), (gt_depths).(*), (gt_ref_depths).(*), (gt_alt_depths).(*), (gt_quals).(*) FROM variants WHERE (impact_severity = 'HIGH' OR impact_severity = 'MED') AND (aaf_1kg_all &lt; 0.01 OR aaf_1kg_all is null) AND (aaf_esp_all &lt; 0.01 OR aaf_esp_all is null) AND (aaf_exac_all &lt; 0.01 OR aaf_exac_all is null);\" --header variants/HC.chr5.60Mb.vep.vcf.db &gt; variants/gemini-result.tsv\n</code></pre> <p>Notice that we have added a WHERE statement which restricts the rows that are returned based on values that we specify for specific columns. Here, we are asking to return variants where their impact on the gene (impact_severity column) is medium or high and the allele frequency in 1000Genomes, ESP and EXaC is less than 1% or the variant is not present in any of these databases.</p> <p>Now let\u2019s open the result in a spreadsheet to look at the annotations:</p> <pre><code>libreoffice --calc variants/gemini-result.tsv\n</code></pre> <p>Tick the <code>Tab</code> under <code>Separated by</code> on the dialog window that comes up.  </p> <p>You can see that the first 14 columns contain information on the variant including its location, ref, alt, dbSNP ID, quality and type. Slowly scroll to the right and look at the columns of data that are provided. Most importantly, column BD includes the gene this variant impacts, BN the impact itself and BP the impact severity. Scroll towards the end of the spreadsheet until you get to columns ED and EE, these contain the genotype for each of the samples. Columns EH and EI contain the total depth for each variant in each sample and the 4 following columns contain the reference and alternate depths for each sample. Finally, columns EN and EO contain the genotype qualities (from the GQ field in the VCF) for each sample. As you scroll back and forth through this spreadsheet, you will see that <code>GEMINI</code> brings in information from a variety of sources including: OMIM, ClinVar, GERP, PolyPhen 2, SIFT, ESP, 1000 Genomes, ExAC, ENCODE, CADD and more! We are only looking at a small number of variants from the start of a chromosome so not many of these annotations will be present but in a full genome database they are incredibly useful.</p> <p><code>GEMINI</code> allows you to filter your variants based on any column that you see in this results file. For example, you may want all variants in a specific gene, in which case you would simply add \u201cWHERE gene = \u2019BRCA1\u2019\u201d to your query. For complete documentation with many examples of queries, see the GEMINI documentation here.</p>"},{"location":"modules/cancer-module-snv/snv/#references","title":"References","text":"<ol> <li> <p>Paila U, Chapman BA, Kirchner R and Quinlan AR. \u201cGEMINI: Integrative     Exploration of Genetic Variation and Genome Annotations\u201d. PLoS     Comput Biol, 2013, 9(7): e1003153. doi:10.1371/journal.pcbi.1003153</p> </li> <li> <p>McLaren W, Pritchard B, Rios D, Chen Y, Flicek P and Cunningham F.     \u201cDeriving the consequences of genomic variants with the Ensembl API     and SNP Effect Predictor\u201d. Bioinformatics, 2010, 26(16):2069-70,     doi:10.1093/bioinformatics/btq330</p> </li> </ol>"},{"location":"modules/cancer-module-snv/snv/#acknowledgements","title":"Acknowledgements","text":"<p>This is based on an Introduction to DNA-Seq processing for cancer data by Mathieu Bourgey, Ph.D.  </p> <p>This tutorial is an adaptation of the one created by Louis letourneau. Mathieu Bourgey would like to thank and acknowledge Louis for this help and for sharing his material. The format of the tutorial has been inspired from Mar Gonzalez Porta. He also wants to acknowledge Joel Fillon, Louis Letrouneau (again), Francois Lefebvre, Maxime Caron and Guillaume Bourque for the help in building these pipelines and working with all the various datasets.</p>"},{"location":"modules/cancer-module-somatic/01_signatures/","title":"Assessing somatic mutational signatures","text":""},{"location":"modules/cancer-module-somatic/01_signatures/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Visualise mutational signatures present in a cohort using somatic     single nucleotide mutation data in Variant Call Format (VCF) files.</p> </li> <li> <p>Compare analysis output with published results to identify common     mutational signatures.</p> </li> <li> <p>Have gained overview knowledge of how somatic signatures can help     with cohort cancer analysis.</p> </li> </ul>"},{"location":"modules/cancer-module-somatic/01_signatures/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-somatic/01_signatures/#tools-used","title":"Tools Used","text":"<p>R-3.2.2 statistical environment: https://www.r-project.org/</p> <p>SomaticSignatures R package: http://bioconductor.org/packages/release/bioc/html/SomaticSignatures.html</p> <p>BSgenome.Hsapiens.UCSC.hg19: http://bioconductor.org/packages/release/data/annotation/html/BSgenome.Hsapiens.UCSC.hg19.html</p> <p>VariantAnnotation: https://bioconductor.org/packages/release/bioc/html/VariantAnnotation.html</p> <p>GenomicRanges: https://bioconductor.org/packages/release/bioc/html/GenomicRanges.html</p> <p>Cairo: https://cran.rstudio.com/web/packages/Cairo/index.html</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#sources-of-data","title":"Sources of Data","text":"<p>TCGA melanoma SNV data: https://tcga-data.nci.nih.gov/tcga/</p> <p>ICGC ovarian SNV data:  https://dcc.icgc.org/</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#useful-links","title":"Useful Links","text":"<p>Variant Call Format (VCF) specification:  http://samtools.github.io/hts-specs/VCFv4.2.pdf</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#author-information","title":"Author Information","text":"<p>Primary Author(s): Ann-Marie Patch, QIMR Berghofer ann-marie.patch@qimrberghofer.edu.au Erdahl Teber, CMRI eteber@cmri.org.au </p> <p>Contributor(s): Martha Zakrzewski Martha.Zakrzewski@qimrberghofer.edu.au</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#introduction","title":"Introduction","text":"<p>The most common genetic model for cancer development is the accumulation of DNA mutations over time, eventually leading to the disruption or dysregulation of enough key genes that lead cells to uncontrolled growth. Cells in our bodies accumulate DNA mutations over time due to normal aging processes and through exposure to carcinogens.</p> <p>Recently researchers found a method to take all the single nucleotide mutations identified in tumour cells (somatic SNVs) and group them together by the type of the mutation and also what the neighbouring bases are. This is commonly referred to as somatic mutational signatures. Common mutational processes that are regularly identified in cancer sequencing are:</p> <ul> <li> <p>Age: the aging process. These are high in C/T transitions due to     deamination of methyl-cytidine.</p> </li> <li> <p>Smoking: marks exposure to inhaled carcinogens and has high numbers     of C/A transversions.</p> </li> <li> <p>UV: UV exposure. These are also high in C/T transitions at     di-pyrimidine sites.</p> </li> <li> <p>BRCA: Indicates that the homologous recombination repair pathway is     defective.</p> </li> <li> <p>APOBEC: Thought to be marking dysregulated APOBEC enzyme activity on     single stranded DNA produced during the repair processing of other     lesions such as double stand breaks.</p> </li> <li> <p>MMR: Mismatch repair pathway not working properly. These are high in     C/T mutations too.</p> </li> </ul> <p> In cohort cancer analysis it is common to try to generate subtypes to group your data based on a particular molecular phenotype. A reason for doing may include finding sets of patients that have a similar form of the disease and therefore all might benefit from a particular treatment. We can use the somatic mutational signatures analysis to group the data from a cohort of patients to inform which genomes are most similar based on the pattern of exposures or processes that have contributed to their genome changes. The patients don\u2019t have to have the same type of cancer so pan-cancer studies are using this analysis to find similarities across cancer types.</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#preparing-the-r-environment","title":"Preparing the R environment","text":"<p>The mathematical framework developed by Alexandrov et al. was implemented in MATLAB. We are going to use a version implemented in R by Gehring et al. called <code>SomaticSignatures package</code>, that is very quick and flexible but currently only accepts point mutations not insertions or deletions (indels). In tests on our data we have found that the Somatic Signatures package in R returns very similar results to the full implementation of Alexandrov\u2019s framework.</p> <p>The data files you will need are contained in the subdirectory called <code>somatic/somatic_signatures</code>:</p> <p>Open the Terminal and go to the <code>somatic_signatures</code> working directory:</p> <pre><code>cd ~/somatic/somatic_signatures\npwd\n</code></pre> <p>In this folder you should find 12 files that end with the extension <code>.vcf</code>. Use the list command to make sure you can see them.</p> <pre><code>ls\n</code></pre> <p>These files contain data extracted from the TCGA melanoma paper and Australian ICGC ovarian paper both mentioned in the introductory slides. They have been edited in order to allow this practical to run quickly and are not good examples of VCF files.</p> <p>Start R and set the working directory. Just start by typing R onto the command line.</p> <pre><code>R\n</code></pre> <p>Load all the package libraries needed for this analysis by running the commands.</p> <pre><code>library(SomaticSignatures)\nlibrary(BSgenome.Hsapiens.UCSC.hg19)\nlibrary(ggplot2)\nlibrary(Cairo)\n</code></pre> <p>Set the directory where any output files will be generated</p> <pre><code>setwd(\"~/somatic/somatic_signatures\")\n</code></pre>"},{"location":"modules/cancer-module-somatic/01_signatures/#loading-and-preparing-the-snv-mutation-data","title":"Loading and preparing the SNV mutation data","text":"<p>The mutations used in this analysis need to be high quality somatic mutations</p> <ul> <li> <p>Remember the goal is to find the key mutational processes that these     tumours have been exposed to, so you need to exclude germline     mutations (mutations that the person was born with that can be seen     in the sequencing of matched normal samples).</p> </li> <li> <p>Sequencing errors can also occur at particular DNA sequence contexts     and can also be picked up using this method. To avoid this use only     high quality mutation calls.</p> </li> </ul> <p>Read in the mutations from the 12 VCF files</p> <pre><code>files &lt;- list.files(\"~/somatic/somatic_signatures\", pattern=\"vcf$\", full.names=TRUE)\n</code></pre> <p>To make sure all the files are listed run the command.</p> <pre><code>files\n</code></pre> <p>You should see a list of 12 sample files.</p> <p>Next read in all the genomic positions of variants in the VCF files using the <code>vranges</code> class.</p> <pre><code>vranges &lt;- lapply(files, function(v) readVcfAsVRanges(v,\"hg19\"))\n</code></pre> <p>Join all the lists of variant positions into one big data set so that it can be processed together and look at what is contained in the concatenated <code>vranges</code> data</p> <pre><code>vranges.cat &lt;- do.call(c,vranges)\nvranges.cat\n</code></pre> <p>The first line of output of the <code>vranges.cat</code> shows us that in total we have put over 100,000 mutations recording the chromosome positions and mutation base changes along with what sample they were seen in.</p> <p>Note there are a lot of NA values in this data set because we have left out non-essential information in order to cut down on the processing time.</p> <p>Next we need to ensure all the positions in the <code>vranges</code> object have been recorded in UCSC notation form so that they will match up with the reference we are using.</p> <pre><code>vranges.cat &lt;- ucsc(vranges.cat)\n</code></pre> <p>It is always important to select the correct reference for your data.</p> <p>We can print out how many mutations we have read in for each of the cancer samples we are using by using the command.</p> <pre><code>print(table(sampleNames(vranges.cat)))\n</code></pre> <p>We have now added all the positional and base change information now we can use the reference and the position of the mutation to look up the bases on either side of the mutation i.e. the mutation context.</p> <p>Run the mutationContext function of SomaticSignatures.</p> <pre><code>mc &lt;- mutationContext(vranges.cat, BSgenome.Hsapiens.UCSC.hg19)\n</code></pre> <p>We can inspect what information we had added to the <code>vranges.cat</code> object by typing <code>mc</code> on the command line. Notice that the mutation and its context have been added to the last two columns.</p> <pre><code>mc\n</code></pre>"},{"location":"modules/cancer-module-somatic/01_signatures/#snv-mutation-context","title":"SNV mutation context","text":"<p>There are a total of 96 possible single base mutations and context combinations. We can calculate this by listing out the six possible types of single nucleotide mutations:</p> <pre>\n  -   C/A   the reverse compliment (G/T) is also in this group\n  -   C/G   includes (G/C)\n  -   C/T   includes (G/C)\n  -   T/A   includes (A/T)\n  -   T/C   includes (A/G)\n  -   T/G   includes (A/C)\n  </pre> <p>The neighbouring bases, on either side of a mutation, are referred to as the mutation context. There are 16 possible combinations of mutation contexts. Here [.] stands for one of the mutations listed above.</p> <pre>\n  -   A[.]A   A[.]C   A[.]G   A[.]T\n  -   C[.]A   C[.]C   C[.]G   C[.]T\n  -   G[.]A   G[.]C   G[.]G   G[.]T\n  -   T[.]A   T[.]C   T[.]G   T[.]T\n  </pre> <p>Now if we substitute the [.]\u2019s with each of the 6 different mutations you will find there are 96 possible types of combined mutations and contexts (6 x 16).</p> <p>Start by substituting [.] for the A/C mutation type</p> <pre>\n  -   A[C/A]A\n  -   A[C/A]C\n  -   A[C/A]G\n  -   A[C/A]T\n  -   C[C/A]A\n  -   C[C/A]C\n  -   C[C/A]G\n  </pre> <p>and so on\u2026</p> <p>We assign all the somatic mutations identified in a single tumour to one of these categories and total up the number in each.</p>  <p>Question</p> <p>What about a mutation that looks like G[A/C]A, where should this go?</p>   Hint <p>Remember to reverse compliment all the nucleotides.</p>     Answer <p>In the T[T/G]C context count.</p>    <p> Now we have all the information that is needed for each sample we can make a matrix that contains counts of mutations in each of the 96 possible combinations of mutations and contexts counting up the totals separately for each sample</p> <pre><code>mm &lt;- motifMatrix(mc, group = \"sampleNames\", normalize=TRUE)\ndim(mm)\n</code></pre> <p>The output of the <code>dim(mm)</code> command show us that there are 96 rows (these are the context values) and 12 columns which are the 12 samples.</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#running-the-nmf-analysis","title":"Running the NMF analysis","text":"<p>Using the matrix we have made we can now run the non-negative matrix factorisation (NMF) process that attempts to find the most stable, grouping solutions for all of the combinations of mutations and contexts. It does this by trying to find similar patterns, or profiles, amongst the samples to sort the data into firstly just 2 groups. This is repeated to get replicate values for each attempt and then separating the data by 3 groups, and then 4 and so on.</p> <p>These parameter choices have been made to keep running time short for this practical. If you have more samples from potentially diverse sources you may need to run with a larger range of signatures and with more replicates.</p> <p>To find out how many signatures we have in the data run the command.</p> <pre><code>gof_nmf &lt;- assessNumberSignatures(mm, 2:10, nReplicates = 5)\n</code></pre> <p>Visualise the results from the NMF processing by making a pdf of the plot</p> <pre><code>pdf(file=\"plotNumberOfSignatures.pdf\", width=9, height=8)\nplotNumberSignatures(gof_nmf)\ndev.off()\n</code></pre> <p>Open up the PDF and examine the curve. The plotNumberOfSignatures PDF that will have been made in the working directory that you set up at the beginning</p> <p> Figure 1: This plot is used to find the number of signatures that is likely to be the best grouping solution. The top plot shows the decreasing residual sum of squares for each increasing number of signatures and the bottom plot the increasing explained variance as the number of potential signatures increases. Ideally the best solution will be the lowest number of signatures with a low RSS and a high explained variance.</p> <p> Look at the y-axis scale on the bottom panel of Figure 1. The explained variance is already very high and so close to finding the correct solution for the number of signatures even with just 2. The error bars around each point are fairly small considering we have a very small sample set. Deciding how many signatures are present can be tricky but here let\u2019s go for 3. This is where the gradient of both curves have started to flatten out.</p> <p>Now run the NMF again but this time stipulating that you want to group the data into 3 different mutational signatures.</p> <pre><code>  sigs_nmf = identifySignatures(mm, 3, nmfDecomposition)\n</code></pre> <p>Visualise the shape of the profiles for these 3 signatures</p> <pre><code>  pdf(file=\"plot3Signatures.pdf\", width=10, height=8)\n  plotSignatures(sigs_nmf,normalize=TRUE, percent=FALSE) + ggtitle(\"Somatic Signatures: NMF - Barchart\") + scale_fill_brewer(palette = \"Set2\")\n  dev.off()\n</code></pre> <p>Open up <code>plot3Signatures.pdf</code> that will have been made in the working directory.</p> <p>You should have generated a plot with three signature profiles obtained from the NMF processing of the test dataset.</p> <p>The 96 possible mutation/context combinations are plotted along the x axis arranged in blocks of 6 lots of 16 (see information above). The height of the bars indicates the frequency of those particular mutation and context combinations in each signature.</p> <p>Although the section colours are different to the plot you have generated the mutations are still in the same order across the plot.</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#interpreting-the-signature-results","title":"Interpreting the signature results","text":"<p>In their paper Alexandrov et al. used this analysis to generate profiles from the data for more than 7000 tumour samples sequenced through both exome and whole genome approaches. They were able to group the data to reveal which genomes have been exposed to similar mutational processes contributing to the genome mutations.</p> <p> Figure 2. The 96 possible mutation/context combinations are plotted along the x axis arranged in blocks of 6 lots of 16. The y axis indicates the frequency of those particular mutation and context combinations in each signature. Source: Alexandrov et al. Nature 2013</p>   <p>Question</p> <p>Can you match up, by eye, the profile shapes against a selection of known mutational signatures supplied (Figure 2)?</p> <p>Try to match up the patterns made by the positions of the highest peaks for each signature.</p>   Answer <ul> <li> <p>Alexandrov signature 7 matches with our signature 1</p> </li> <li> <p>Alexandrov signature 13 matches with our signature 2</p> </li> <li> <p>Alexandrov signature 3 matches with our signature 3</p> </li> </ul>    <p> Now use the table from Alexandrov et al. to identify which mutational processes our three generated signatures have been associated with.</p> <p> Figure 3. The 21 signatures identified are indicated as rows with the number corresponding to Figure 2 on the left. The types of tumours used in the analysis are listed as columns. A green dot at the intersection of a signature and tumour indicates the signature was identified in that sample type. Where verified the mutational process is listed on the right. Source: Alexandrov et al. Nature 2013</p>   <p>Question</p> <p>What mutational mechanisms have been associated with the signatures that you have generated?</p>   Answer <ul> <li> <p>Our signature 1 (AS7) is associated with Ultraviolet radiation     damage to DNA. This has previously been identified in Head and Neck     and Melanoma cancer samples.</p> </li> <li> <p>Our signature 2 (AS 13) is associated with the activity of     anti-viral APOBEC enzymes. This has previously been seen in Breast     and Bladder cancer samples.</p> </li> <li> <p>Our signature 3 (AS3) is associated with BRCA1 and BRCA2 mutations,     i.e. the homologous recombination repair pathway not working     properly. This has been seen in Breast, Ovarian and Pancreas cancer     samples.</p> </li> </ul>    <p> Now we can plot out the results for the individual samples in our dataset to show what proportion of their mutations have been assigned to each of the signatures.</p> <pre><code>pdf(file=\"PlotSampleContribution3Signatures.pdf\", width=9, height=6)\nplotSamples(sigs_nmf, normalize=TRUE) + scale_y_continuous(breaks=seq(0, 1, 0.2), expand = c(0,0))+ theme(axis.text.x = element_text(size=6))\ndev.off()\n</code></pre> <p>If you don\u2019t have time to carry out the advanced questions you can exit R and return to the normal terminal command line.</p> <pre><code>quit()\nn\n</code></pre> <p> Open the resulting <code>PlotSampleContribution3Signatures.pdf</code>.  </p> <p>This shows the results for the mutation grouping for each sample. The samples are listed on the x-axis and the proportion of all mutations for that sample is shown on the y-axis. The colours of the bars indicate what proportion of the mutations for that sample were grouped into each of the signatures. The colour that makes up most of the bar for each sample is called its \u201cmajor signature\u201d.</p> <p>The data you have been using contains samples from High Grade Serous Ovarian Carcinomas and Cutaneous Melanoma. </p>  <p>Question</p> <p>Using the major signature found for each sample can you guess which are ovarian and which are melanoma samples?</p>   Answer <ul> <li> <p>Samples 9-12 have the majority signature of our signature 1. This is     the UV signature and so these are likely to be Melanoma samples.</p> </li> <li> <p>Samples 4-8 have the majority signature of our signature 3. This is     the BRCA signature and these are most likely to be ovarian samples.</p> </li> <li> <p>Samples 1-3 have the majority signature of our signature 2. This is     the APOBEC signature indicating activity of the anti-viral APOBEC     enzymes. These are less likely to be from cutaneous melanoma because     they have very few UV associated mutations although it could     possibly be from a different subtype. However it is much more likely     that these will be ovarian tumours as this APOBEC signature has been     seen in breast tumours which can be similar to ovarian cancers in     terms of the mutated genes.</p> </li> </ul>     <p>Question</p> <p>This is an open question for discussion at the end of the practical.</p> <p>How can this analysis be useful for cancer genomics studies?</p>   <p>Advanced exercise</p> <p>Now rerun the process this time using 4 signatures as the solution.</p>   Hint <p>You don\u2019t have to start back at the beginning but you can jump to the step where you run the NMF but this time for 4 instead of 3 signatures. Then continue through making the plots. You will need to change the name of each plot you remake with 4 signatures because Cairo won\u2019t let you overwrite and existing file.</p>   <p>Can you find a good match in the set of known signatures for all 4 patterns?</p> <p>Can you find a verified process for all of the profiles you are seeing?</p>"},{"location":"modules/cancer-module-somatic/01_signatures/#references","title":"References","text":"<p>Alexandrov et al. Nature 2013:  http://www.nature.com/nature/journal/v500/n7463/pdf/nature12477.pdf</p> <p>Gehring et al. Bioinformatics 2015:  http://bioinformatics.oxfordjournals.org/content/early/2015/07/31/bioinformatics.btv408.full</p>"},{"location":"modules/cancer-module-somatic/02_intogen/","title":"Cohort analysis for the identification of driver genes","text":""},{"location":"modules/cancer-module-somatic/02_intogen/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li> <p>Run the <code>IntOGen</code> analysis software on cohort mutation data.</p> </li> <li> <p>Have gained experience of the structure of the analysis output files     in order to identify potential driver genes.</p> </li> <li> <p>Have gained overview knowledge of different methods for     identification of genes important in cancers.</p> </li> </ul>"},{"location":"modules/cancer-module-somatic/02_intogen/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-somatic/02_intogen/#tools-used","title":"Tools Used","text":"<p>IntOGen mutations platform: https://www.intogen.org/search</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#sources-of-data","title":"Sources of Data","text":"<p>TCGA melanoma somatic SNV data from 338 tumour samples: https://tcga-data.nci.nih.gov/tcga/</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#useful-links","title":"Useful Links","text":"<p>Mutation Annotation Format (MAF) specification: https://wiki.nci.nih.gov/display/TCGA/Mutation+Annotation+Format+(MAF)+Specification</p> <p>IntOGen installation instructions: https://bitbucket.org/intogen/intogen-pipeline/overview</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#author-information","title":"Author Information","text":"<p>Primary Author(s): Ann-Marie Patch, QIMR Berghofer ann-marie.patch@qimrberghofer.edu.au Erdahl Teber, CMRI eteber@cmri.org.au </p> <p>Contributor(s): Scott Wood scott.wood@qimrberghofer.edu.au </p>"},{"location":"modules/cancer-module-somatic/02_intogen/#introduction","title":"Introduction","text":"<p>Cancer driver genes are commonly described as genes that when mutated directly affect the potential of a cell to become cancerous. They are important to a tumour cell as they confer a growth or survival advantage over the normal surrounding cells. The mutations in these driver genes are then clonally selected for as the population of tumour cells increases. We think of the key genes driving tumour initiation (development), progression, metastases, resistance and survival. Driver gene mutations are often described as \u201cearly\u201d events because they were key in turning a normally functioning and regulated cell into a dysregulated one. The logical assumption is that these key mutations will be present in all tumour cells in a patient\u2019s sample; although sometime this is not true.</p> <p>There are two major research goals that underline the need to identify driver genes:</p> <ul> <li> <p>By identifying the early changes that take place researchers might     be able to find a treatment to stop the root cause of why cells     become malignant.</p> </li> <li> <p>By identifying groups of patients with the same genes mutated then     we can develop therapies that will work for all of them.</p> </li> </ul> <p>When we sequence tumour samples we tend to use samples that come from fully developed cancers that can carry hundreds to thousands of mutations in genes and many more outside of genes. The accumulation of these passenger mutations in cancer cells can happen because often the repair mechanisms or damage sensing processes are amongst the first pathways to become disrupted accelerating the mutational rate. Mutations that occur in genes after the cell has become cancerous may still affect the growth rate, invasiveness and even the response to chemotherapy but may not be present in all cells of a tumour. These genes may be drivers of chemo-resistance or metastasis and are equally good targets for therapies.</p> <p>IntOGen-mutations is a platform that aims to identify driver mutations using two methodologies from cancer cohort mutation data: the first identifies mutations that are most likely to have a functional impact combined with identifying genes that are frequently mutated; and the second, genes that harbour clustered mutations. These measures are all indicators of positive selection that occurs in cancer evolution and may help the identification of driver genes.</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#analysing-cancer-cohort-data-with-intogen","title":"Analysing cancer cohort data with IntOGen","text":"<p>IntOGen-mutations is available as a web based service that can allow users to run their analysis on the host\u2019s servers or it can be downloaded and run on a local server.</p> <p>For the purposes of the course we will be using a local version of <code>IntOGen</code> so that we don\u2019t encounter any issues sharing resources.</p> <ul> <li> <p>To begin open a terminal and navigate to the directory <code>somatic/intogen</code>.</p> <pre><code>cd ~/somatic/intogen\n</code></pre> </li> </ul> <p>In this directory you will find a Mutation Annotation Format (MAF) file containing a cut down version of the somatic variant calls identified from melanoma samples investigated as part of the TCGA cancer genomics projects. You can see what files are in the directory by typing <code>ls</code>, look inside the file using <code>less TCGA_Melanoma_SMgene.maf</code> and close the file and return to the command line by typing <code>q</code>.</p> <ul> <li> <p>Run the <code>IntOGen</code> analysis by typing</p> <pre><code>intogen -i TCGA_Melanoma_slimSMgene.maf -o TCGA_Mela_out\n</code></pre> </li> </ul> <p>The TCGA melanoma maf used in this practical has been modified from the original to reduce processing time and only contains data for the top 680 mutated genes.</p> <p>The tool will take around 10 minutes to run and the progress will be indicated by the logging lines printed to the terminal. Once complete the output can be explored.</p> <p>Whilst the tool is running we can explore the options we have used to run <code>IntOGen</code>.</p> <ul> <li>To get a list of <code>IntOGen</code> options open up a new terminal</li> </ul> <pre><code>intogen --help\n</code></pre> <p>This command will list the running options that you can alter as command line inputs or in a configuration file. We are using the default options for this run so we didn\u2019t have to supply a configuration file and we only used <code>-i</code> to set the input and <code>-o</code> to control the mane of the output directory.</p> <ul> <li>To look at the default options open up the configuration file by typing  </li> </ul> <pre><code>less ~./intogen/task.conf  \nless ~./intogen/system.conf\n</code></pre> <p>It is important to set the correct genome assembly in the <code>task.conf</code> to match the one that you used as your reference when the variant were called. In our <code>task.conf</code> this should be <code>hg19</code>.</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#exploring-the-output-of-intogen","title":"Exploring the output of IntOGen","text":"<p>When you run your data over the web on the remote site there is a browse facility that allows you to explore your data using the web version of the database. Running <code>IntOGen</code> locally provides the same tabular information but in a flat file format.</p> <p>There should be 14 files generated from a successful run of this version of <code>IntOGen</code>:</p> <pre><code>gene.tsv\ngene.oncodriveclust\npathway.recurrences\ngene.oncodrivefm\nsample_gene.impact\ngene.recurrences                                \nsample_variant+transcript.impact\nsummary.tsv\ntranscript.recurrences\nTCGA_Melanoma_slimSMgene.smconfig\noncodrivefm-pathways-MA_SCORE.tsv\noncodrivefm-pathways-PPH2_SCORE.tsv  \noncodrivefm-pathways-SIFT_SCORE.tsv  \npathway.oncodrivefm\n</code></pre> <p>View these files by using <code>ls</code> as below.</p> <pre><code>ls ~/somatic/intogen/TCGA_Mela_out/project/TCGA_Melanoma_slimSMgene/\n</code></pre> <p>This practical will concentrate on the identification of driver genes so we will look at the main output concerning genes. The <code>gene.tsv</code> is the main gene centric output summary table.</p> <ul> <li> <p>Open up the <code>gene.tsv</code> file in <code>LibreOffice</code> by double clicking on the icon on your desktop.</p> </li> <li> <p>Select the file tab and click on open.</p> </li> <li> <p>Navigate to the results directory <code>~/somatic/intogen/TCGA_Mela_out/project/TCGA_Melanoma_slimSMgene/</code></p> </li> <li> <p>Double click on <code>gene.tsv</code>.</p> </li> <li> <p>In the pop-up box under the <code>Separator options</code> ensure only the tab box is checked and click <code>OK</code>.</p> </li> </ul> <p>This file contains the overall summary results for the <code>IntOGen</code> pipeline presented by gene and reports Q values (i.e. multiple testing corrected P values) for the mutation frequency and cluster modules.</p> <p>Significantly mutated genes from the cohort data are identified using both the <code>OncodriveFM</code> and <code>OncodriveClUST</code> modules of <code>IntOGen</code>. The <code>OncodriveFM</code> module detects genes that have accumulated mutations with a high functional impact. It uses annotations from the Ensembl variant effect predictor (VEP, V.70) that includes SIFT and Polyphen2 and precomputed MutationAssessor functional impacts. It calculates a P value per gene from the number of mutations detected across all possible coding bases of a gene with a positive weighting for mutations with a high functional impact. The <code>OncodriveCLUST</code> module detects genes that have more variants than would be expected across the cohort that alter the same region of the gene.</p> <p>The file is sorted to bring the most significantly altered genes to the top. The key columns that help you identify the significantly mutated genes are the 3rd and 4th (C and D) that indicate which of the modules identified a significant result and the Q-values for the modules that are in 21st and 23rd (U and W)</p> <p>The top twelve genes have significant Q-values for both modules and include BRAF, NRAS and TP53. The next 35 are significant by only one of the modules.</p> <p>All of these have small Q-values which means they are all significantly mutated genes in this TCGA Melanoma cohort of 338 patients.</p> <ul> <li>Now look at their sample frequency count (column 9 <code>MUTS_CS_SAMPLES</code>) these are the number of samples that contain at least one mutation in the gene.</li> </ul>  <p>Question</p> <p>a)   Which significantly mutated gene has mutations in the most samples?</p> <p>b)   Which gene/genes have the lowest Q-value from OncodriveFM and OncodriveCLUST?</p> <p>c)   Why don\u2019t the genes with the lowest Q values also have the highest sample frequency value?</p>   Answer <p>a)  BRAF has 175 out of 327 cases with a mutation.</p> <p>b)  TP53 or PTEN have the lowest OncodriveFM Q-values and NRAS has the lowest Q-value for OncodriveCLUST.</p> <p>c)  The P value calculation takes into account the length of the     coding sequence of the gene, the mutation rate of the nucleotides     contained within it and for OncodriveFM the functional consequences     of those changes. Therefore a small gene with a small number of deleterious     mutations may have a lower P value and also Q value than a large     gene with a high mutation frequency.</p>    <p>The results for the assessment of clustered mutations in genes carried out by the <code>OncodriveCLUST</code> module of <code>IntOGen</code> are shown as  amino acid residue positions of the encoded protein.</p> <p>The three known oncogenes BRAF, NRAS and IDH1 have very low CLUST_QVALUEs indicating that the mutations in these genes are highly clustered. The <code>CLUST_COORDS</code> column reports that there are 160 samples with mutations between the amino acid positions 594-601 of BRAF; 84 samples with mutations at amino acid position 61 of NRAS; and 15 sample with mutations at amino acid position 132 of IDH1.</p>  <p>Question</p> <p>Why are the oncogenes more likely to have clustered mutations and the tumour suppressor genes less likely?</p>   Answer <p>Gain of function mutations are required to activate oncogenes and so only key residues in the protein will result in activation. Tumour suppressors are frequently affected by loss of function mutations and deletions. A truncating mutation or frameshift indel can occur in any exon, except the last one, and have the same deleterious functional result.</p>    <p> The other files in the output support the information in this sheet.</p> <p>The <code>sample_variant+transcript.impact</code> file includes a summary of all mutations found in each of the genes and protein coding transcripts of those genes for all samples identified that have that mutation. It also reports the variant impact scores from SIFT, PolyPhen2, MutationAssesor, reporting also impact categories of which there are four; high, medium, low and none.</p> <ul> <li>Open up the <code>sample_variant+transcript.impact</code> file and explore the data.</li> </ul>  <p>Question</p> <p>Can you find out what the nucleotide change details for the most common BRAF mutation that results in V600E amino acid change in the cohort? Sort the data by GENE, then TRANSCRIPT and then PROTEIN_POS to make this easier. The gene ID for BRAF is <code>ENSG00000157764</code>.</p>   Answer <p>It is an A&gt;T at position chr7:140453136 identified in 127 samples.</p>"},{"location":"modules/cancer-module-somatic/02_intogen/#references","title":"References","text":"<p>Gunes et al. Nat. Methods 2010 :   http://www.nature.com/nmeth/journal/v7/n2/pdf/nmeth0210-92.pdf</p> <p>Gonzalez-Perez et al. Nat. Methods 2013 :   http://www.nature.com/nmeth/journal/v10/n11/pdf/nmeth.2642.pdf</p>"},{"location":"modules/cancer-module-sv/sv_tut/","title":"Structural Variant Analysis","text":""},{"location":"modules/cancer-module-sv/sv_tut/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>By the end of the structural variant (SV) detection practical course participants will:</p> <ul> <li> <p>Have been provided with key fundamentals on how paired-end mappings     and split-read/soft-clipped read patterns are used in detecting     deletions, tandem duplicates, inversions and translocations.</p> </li> <li> <p>Know what important quality control checks need to be evaluated     prior to structural variant calling.</p> </li> <li> <p>Have run <code>DELLY</code> on a subset of whole genome next generation     sequencing data pertaining to a single human tumour with a matched     normal control.</p> </li> <li> <p>Be able to filter high confidence SV predictions.</p> </li> <li> <p>Have gained basic knowledge to interpret the VCF output provided by     DELLY.</p> </li> <li> <p>Have used their understanding of distinct SV paired-end mapping and     soft-clipped read patterns to visually verify <code>DELLY</code> predicted SVs     using <code>IGV</code>.</p> </li> </ul>"},{"location":"modules/cancer-module-sv/sv_tut/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-sv/sv_tut/#tools-used","title":"Tools Used","text":"<p>DELLY: https://github.com/tobiasrausch/delly</p> <p>Samtools: http://sourceforge.net/projects/samtools/files/samtools/1.2</p> <p>Tabix: http://sourceforge.net/projects/samtools/files/tabix/tabix-0.2.6.tar.bz2</p> <p>Vcftools: https://vcftools.github.io/index.html</p> <p>Picard: https://broadinstitute.github.io/picard/</p> <p>Python2.7.10: https://www.python.org/downloads/release/python-2710/</p> <p>PyVCF Banyan numpy: https://pypi.python.org/pypi</p>"},{"location":"modules/cancer-module-sv/sv_tut/#useful-links","title":"Useful Links","text":"<p>SAM Specification: http://samtools.sourceforge.net/SAM1.pdf</p> <p>Explain SAM Flags: https://broadinstitute.github.io/picard/explain-flags.html</p>"},{"location":"modules/cancer-module-sv/sv_tut/#author-information","title":"Author Information","text":"<p>Primary Author(s):  Erdahl Teber eteber@cmri.org.au Ann-Marie Patch Ann-Marie.Patch@qimrberghofer.edu.au</p> <p>Contributor(s):  Sonika Tyagi sonika.tyagi@agrf.org.au</p>"},{"location":"modules/cancer-module-sv/sv_tut/#alignment-quality-control","title":"Alignment Quality Control","text":"<p>For structural variant calling several alignment quality control metrics should be evaluated. All paired-end mapping methods heavily rely on the insert size distribution. GC-content biases are important as it can impact read-depths. <code>DELLY</code> generates read-depth ratios between tumour and control samples. The percentage of mapped reads, singletons, duplicates and properly paired reads are additional metrics you should evaluate prior to any structural variant calling. These statistics vary largely by protocol and hence, it is usually best to compare multiple different sequencing runs using the same against each other to highlight outliers.</p> <p>It is recommended that Picard module commands <code>CollectInsertSizeMetrics</code> and <code>CollectGcBiasMetrics</code>, and <code>samtools flagstat</code> command be used.</p>"},{"location":"modules/cancer-module-sv/sv_tut/#prepare-the-environment","title":"Prepare the Environment","text":"<p>As a quick introduction we will do a structural variant analysis using a single immortal cancer cell line and its control genome (mortal parental cells). Total execution time to run the <code>DELLY</code> structural discovery calling program for a matched normal tumour pair will vary depending on the read coverage and the size of the genome. As a guide, it can take approximately 10 to 50 hours (translocation predictions taking the longest), for a matched normal tumour pair (each 40-50x coverage) running on 2 cpus on a server with sufficient RAM.</p> <p>The bam files we will be working on are a subset of the original WGS bam files, limited to specific chromosomal regions to speed up the analysis and to meet the time constraints for this practical.</p> <p>Firstly, we will use shell variables to help improve the readability of commands and streamline scripting. Each distinct variable will store a directory path to either, the input WGS bam files, hg19 reference, programs or output.</p> <p>Open the Terminal.</p> <p>First, go to the right folder, where the data are stored.</p> <pre><code>cd /home/trainee/sv\nls\nmkdir &lt;YourFirstName&gt;\ncd &lt;YourFirstName&gt;\n\nexport DS=/home/trainee/sv/data\nexport RF=/home/trainee/sv/reference_data\nexport SF=/home/trainee/sv/variantFiltering/somaticVariants\nexport BR=/home/trainee/snv/Applications/igv\nexport CZ=/home/trainee/sv/converter\n</code></pre>"},{"location":"modules/cancer-module-sv/sv_tut/#somatic-structural-variant-discovery-using-delly","title":"Somatic Structural Variant Discovery using DELLY","text":"<p>In order to generate putative somatic SVs it is crucial to account for germline SVs. To facilitate, DELLY requires the joint input of a match normal control and the cancer aligned sequencing data (bam files).</p> <pre><code>delly -t DEL -x $RF/hg19.excl -o del.vcf -g $RF/hg19.fa $DS/cancer_cell_line.bam $DS/control.bam\ndelly -t DUP -x $RF/hg19.excl -o dup.vcf -g $RF/hg19.fa $DS/cancer_cell_line.bam $DS/control.bam\ndelly -t INV -x $RF/hg19.excl -o inv.vcf -g $RF/hg19.fa $DS/cancer_cell_line.bam $DS/control.bam\ndelly -t TRA -x $RF/hg19.excl -o tra.vcf -g $RF/hg19.fa $DS/cancer_cell_line.bam $DS/control.bam\n</code></pre> <p>Description of the arguments used in the command:</p>  <p>DEL: conduct deletion discovery DUP: conduct tandem duplication discovery INV: conduct inversion discovery TRA: conduct translocation discovery -o: vcf output -g: reference genome in FASTA format -x: genomic regions to exclude (e.g. centro- and telomeric regions)  </p>"},{"location":"modules/cancer-module-sv/sv_tut/#delly-vcf-output","title":"DELLY VCF output","text":"<p>A VCF file has multiple header lines starting with the hash <code>#</code> sign. There is one record for each unique structural variant. The record format is described in the table below:</p>    Column Field Description     1 CHROM Chromosome name   2 POS 1-based position. For an indel, this is the position preceding the indel   3 ID Variant identifier   4 REF Reference sequence at POS involved in the variant   5 ALT Comma delimited list of alternative sequence(s)   6 QUAL Phred-scaled probability of all samples being homozygous reference   7 FILTER Semicolon delimited list of filters that the variant fails to pass   8 INFO Semicolon delimited list of variant information   9 FORMAT Colon delimited list of the format of sample genotypes in subsequent fields   10+  Individual genotype information defined by FORMAT    <p>You can look at the header of the vcf file and the first structural variant record in the file using the below command (-A is the option which prints the specified N lines after the match):</p> <pre><code>grep \"^#\" -A 1 del.vcf\n</code></pre> <p> The INFO field holds structural variant site information whereas all genotype information (annotated as per the FORMAT fields) is provided in the sample column. Reference supporting reads are compared to alternative supporting reads and mapping qualities are used to compute genotype likelihoods (GL) for homozygous reference (0/0), heterozygous reference (0/1) and homozygous alternate (1/1) (GT). The final genotype (GT) is simply derived from the best GL and GQ is a phred-scaled genotype quality reflecting the confidence in this genotype. If GQ&lt;15 the genotype is flagged as LowQual. The genotyping takes into account all paired-ends with a mapping quality greater than 20 by default.</p> <p>The INFO field provides information on the quality of the SV prediction and breakpoints. If you browse through the vcf file you will notice that a subset of the DELLY structural variant predictions have been refined using split-reads. These precise variants are flagged in the vcf info field with the tag <code>PRECISE</code>. To count the number of precise and imprecise variants you can simply use <code>grep</code>.</p> <pre><code>grep -c -w \"PRECISE\" *.vcf\ngrep -c -w \"IMPRECISE\" *.vcf\n</code></pre> <p> DELLY clusters abnormal paired-ends and every single cluster gives rise to an <code>IMPRECISE</code> SV call. For every <code>IMPRECISE</code> SV call an attempt is made to identify supporting split-reads/soft-clipped reads. DELLY then computes a consensus sequence (INFO:CONSENSUS) out of all split-read candidates and then aligns this consensus sequence to the reference requiring at least -m many aligned bases to the left and right (default is 13). INFO:PE is the number of supporting paired-ends. INFO:CT refers connection types (CT), which indicates the order and orientation of paired-end cluster mappings (e.g. 3to3 for 3\u2019 to 3\u2019 and 5to5 for 5\u2019 to 5\u2019). Values can be 3to5, 5to3, 3to3 or 5to5. Different names exist for these connection types in the literature, head-to-head inversions, tail-to-tail inversions, and so on. The consensus alignment quality (SRQ) is a score between 0 and 1, where 1 indicates 100% identity to the reference. Nearby SNPs, InDels and micro-insertions at the breakpoint can lower this score but only for mis-assemblies it should be very poor. DELLY currently drops consensus alignments with a score &lt;0.8 and then falls back to an <code>IMPRECISE</code> prediction.</p> <p>SVs are flagged as FILTER:LowQual if PE &lt;3 OR MAPQ &lt;20 (for translocations: PE &lt;5 OR MAPQ &lt;20), otherwise, the SV results in a FILTER:PASS. <code>PRECISE</code> variants will have split-read support (SR &gt;0).</p>"},{"location":"modules/cancer-module-sv/sv_tut/#somatic-structural-variant-filtering","title":"Somatic Structural Variant Filtering","text":"<p>Please note that this vcf file contains germline and somatic structural variants but also false positives caused by repeat induced mis-mappings or incomplete reference sequences. As a final step we have to use the structural variant site information and the cancer and normal genotype information to filter a set of confident somatic structural variants. DELLY ships with a somatic filtering python script. For a set of confident somatic calls one could exclude all structural variants &lt;400bp, require a minimum variant allele frequency of 10%, no support in the matched normal and an overall confident structural variant site prediction with the VCF filter field being equal to PASS.</p> <pre><code>python $SF/somaticFilter.py -t DEL  -T cancer_cell_line -N control -v del.vcf -o del.filt.vcf -a 0.1 -m 400 -f\npython $SF/somaticFilter.py -t DUP -T cancer_cell_line -N control -v dup.vcf -o dup.filt.vcf -a 0.1 -m 400 -f\npython $SF/somaticFilter.py -t INV  -T cancer_cell_line -N control -v inv.vcf -o inv.filt.vcf -a 0.1 -m 400 -f\npython $SF/somaticFilter.py -t TRA -T cancer_cell_line -N control -v tra.vcf -o tra.filt.vcf -a 0.1 -m 400 -f\n</code></pre> <p> Using <code>VCFtools</code> we can merge all somatic structural variants together in a single vcf file.</p> <pre><code>vcf-concat del.filt.vcf dup.filt.vcf inv.filt.vcf tra.filt.vcf | vcf-sort &gt; somatic.sv.vcf\n</code></pre> <p> For large VCF files you should also zip and index them using <code>bgzip</code> and <code>tabix</code>. Please run the below commands to meet the requirements for visualising somatic structural variants using <code>IGV</code>.</p> <pre><code>bgzip -c somatic.sv.vcf &gt; somatic.sv.vcf.gz\ntabix somatic.sv.vcf.gz\n</code></pre>"},{"location":"modules/cancer-module-sv/sv_tut/#visualisation-of-somatic-structural-variants","title":"Visualisation of Somatic Structural Variants","text":"<p>The final step will be to browse some of these somatic structural variants in IGV and to visually verify the reliability of the calls. To make it easy to navigate through our breakpoints of interest we will create a bed file (0-index co-ordinate format file).  </p> <pre><code>$CZ/sv.vcf2bed.sh somatic.sv.vcf.gz &gt; somatic.sv.bed\nhead somatic.sv.bed\n</code></pre> <p> Load the IGV browser</p> <pre><code>$BR/igv.sh &amp;\n</code></pre> <p> Once IGV has started use <code>File</code> and <code>Load from File</code> (directory /home/trainee/sv/data) to load the <code>cancer_cell_line.bam</code> and the <code>control.bam</code>. Go to <code>View</code> menu and select <code>Preferences</code>, then click on the Alignments tab and in the <code>Visibility range threshold (kb)</code> text box, enter 600. This will allow you to increase your visibility of pile ups as you zoom out. Now look for check box for <code>Filter secondary alignments</code>. Ensure box is ticked so that you do not see secondary alignments (alternate mapped position of a read). Also ensure that <code>Show soft-clipped bases</code> has been checked then click <code>OK</code>.</p> <p>Then import <code>somatic.sv.bed</code> from your working directory using <code>Regions</code> and <code>Import Regions</code>.</p>"},{"location":"modules/cancer-module-sv/sv_tut/#verify-deletion","title":"Verify Deletion","text":"<p>This is an advanced section. </p>  <p>The somatic structural variants can then be browsed easily using the <code>Region Navigator</code>. Select the deletion (chrX:76853017-77014863) from the <code>Region Navigator</code> and click <code>View</code>. This will centre the IGV alignment view on the selected structural variant. Close the regions of interest pop up window by right clicking mouse at the top of pop up and then choose close. The red bar below the ruler marks the region of the deletion.</p> <p>It\u2019s usually best to zoom out once by clicking on the <code>-</code> sign in the toolbar at the top, to give a wide view of the supporting abnormal paired-end read mappings.</p> <p>To highlight the abnormal paired-ends right click on the main track display panel and select <code>Color alignments by</code> and then switch to <code>insert size and pair orientation</code>.</p> <p>Read pairs that have a larger than expected insert size will be highlighted in red. Click <code>View as pairs</code>. Right click and <code>Sort alignments by</code> then select <code>start location</code>.</p>   <p>Question</p> <p>How many abnormal paired-end read pairs (red coloured F/R oriented read pairs) can you see that spans the deletion region? Does this number coincide with the INFO:PE?</p>   Hint <pre><code>cat somatic.sv.vcf | grep \"&lt;DEL&gt;\" | cut -f1,2,8\n</code></pre>     Answer <p>19, YES</p>     <p>Question</p> <p>Zoom into left and right breakpoint separately and tally the number of soft-clipped reads (count the soft-clipped reads with &gt;24 mismatched reads). How many abnormal split-reads (soft-clipped reads) did you observe? Clue INFO:SR.</p>   Answer <p>11</p>     <p>Question</p> <p>Go to the RefSeq genes track at the bottom of <code>IGV</code> and right click to <code>Expanded</code>. Is the predicted deletion likely to have a deleterious impact on a gene? If so, what gene and exons are deleted?</p>   Answer <p>ATRX, exons 2 to 25.</p>     <p>Question</p> <p>Does this region appear to be completely removed from this cancer genome? How can you tell?</p>   Answer <p>Yes, there is no read coverage within this deletion region relative to the control genome.</p>"},{"location":"modules/cancer-module-sv/sv_tut/#verify-translocation","title":"Verify translocation","text":"<p>This is an advanced section.</p>  <ul> <li> <p>Remove <code>control.bam</code> and the coverage track by right clicking on the track panel and selecting remove track.</p> </li> <li> <p>Select the translocation breakpoint chr18 from the Region Navigator. Highlight the abnormal paired-ends by clicking and selecting <code>Color alignments by</code> and then switch to <code>insert size and pair orientation</code>. Invoke <code>Sort alignments by</code> then select <code>start location</code>.</p> </li> <li> <p>Zoom out until you can see all the purple reads at the junction.</p> </li> </ul>   <p>Question</p> <p>What is the direction of the purple cluster of reads (indicates that mate reads are mapped to Chr15)? Is it pointing to the tail or head of Chr18?</p>   Answer <p>Forward, towards the tail, or 3\u2019 (+ive)</p>     <p>Question</p> <p>Right click on to one of the purple coloured reads and select <code>View mate region in split-screen</code>. This will split the screen and display Chr15 on the left and place a red highlighted outline on both reads, to indicate the pairs. Select <code>view as pairs</code>, then sort alignments by start location. To control the zooming on each of the chromosome panels, first click inside of the track panel of your chromosome of interest, then to zoom in (<code>Shift</code> and <code>+</code> key together) or out (press <code>Ctrl</code> and <code>-</code> key together).</p> <p>What is the direction of the yellow cluster of reads (indicates that mate reads are mapped to Chr18)? Is it pointing to the tail or head of Chr15? If you wish to zoom in or out, first click inside of the chromosome ideogram panel, then ctrl- to zoom out and shift+ to zoom in.</p>   Answer <p>Reverse, towards the head, or 5\u2019 (+ive)</p>     <p>Question</p> <p>How is the Chr15 and Chr18 fused (which one of the four translocation connection types)? If you are uncertain then run a BLAT (https://genome.ucsc.edu/cgi-bin/hgBlat?command=start) search using the INFO:CONSENSUS sequence.</p>   Hint <pre><code>cat somatic.sv.vcf | grep \"&lt;TRA&gt;\" | cut -f1,2,8\n</code></pre>     Answer <p>RF, head to tail, or 5 to 3. Therefore, Chr18 left side is fused to Chr15 right side.</p>     <p>Question</p> <p>Did DELLY predict a reciprocal translocation? How can you tell?</p>   Answer <p>No, as we would expect to observe a Chr18 right side fused to Chr15 left side, near the same breakpoints.</p>     <p>Question</p> <p>What gene structures is this translocation predicted to impact?</p>   Answer <p>ADAMTSL3 on Chr15 and PARD6G on Chr18.</p>     <p>Question</p> <p>What is one possible reason why there is no observable read coverage after Chr18 breakpoint?</p>   Answer <p>Chromosome loss.</p>"},{"location":"modules/cancer-module-sv/sv_tut/#verify-tandem-duplication","title":"Verify tandem duplication","text":"<p>This is an advanced section.</p>  <ul> <li> <p>Select the tandem duplication (chrX:45649874-45689322) from the <code>Region Navigator</code>.</p> </li> <li> <p>Highlight the abnormal paired-ends by clicking and selecting <code>Color alignments by</code> and then switch to <code>insert size and pair orientation</code>. Also, invoke <code>Sort alignments by</code> then select <code>start location</code>.</p> </li> <li> <p>Zoom out until you can see all the red paired-end reads spanning the two junctions. After that zoom in on the cluster of abnormal reads on the left junction and then right junction.</p> </li> </ul>   <p>Question</p> <p>Which is the order and orientation of these paired-end reads (FR, RF, FF or RR)?</p>   Answer <p>RF</p>     <p>Question</p> <p>What is the estimated read-depth ratio of the cancer_cell_line versus normal control (INFO:RDRATIO) over the duplicate region?</p>   Hint <pre><code>cat somatic.sv.vcf | grep \"&lt;DUP&gt;\" | cut -f1,2,8\n</code></pre>     Answer <p>3.3 (\u00a03 x increased read depth)</p>"},{"location":"modules/cancer-module-sv/sv_tut/#verify-inversion","title":"Verify Inversion","text":"<p>This is an advanced section.</p>  <ul> <li> <p>Type into the search box near at tool bar, Chr20:54834492</p> </li> <li> <p>Right click on main display and select <code>Group alignments by</code> then switch on <code>paired-orientation</code>. Also, right click and <code>Sort alignments by</code> then select <code>start location</code>.</p> </li> <li> <p>Zoom out until you can see all the red coloured cluster of reads near the breakpoint.</p> </li> <li> <p>Right click on to one of the red coloured reads and select <code>View mate region in split-screen</code>. This will split the screen and display the read mate on the right side. This will take you to the mate-reads near the second breakpoint.</p> </li> </ul>   <p>Question</p> <p>Which direction are the paired-end reads spanning (left or right spanning)?</p>   Answer <p>Right</p>     <p>Question</p> <p>What is the estimated size of the inverted interval?</p>   Answer <p>55,408,660 \u2013 54,834,492 = 574,168 bp</p>"},{"location":"modules/cancer-module-sv/sv_tut/#acknowledgements","title":"Acknowledgements","text":"<p>We would like to thank and acknowledge Tobias Rausch (EMBL Heidelberg) for his help and for allowing us to borrow and adapt his replies to questions and original course material.</p>"},{"location":"modules/cancer-module-viz/visu/","title":"Variant Visualisation","text":"<p>Important</p> <p>This is an advanced module.  </p>  <p>This module was written by Mathieu Bourgey and the original on-line version is available here.</p>"},{"location":"modules/cancer-module-viz/visu/#key-learning-outcomes","title":"Key Learning Outcomes","text":"<p>After completing this practical the trainee should be able to:</p> <ul> <li>Generate Circos like graphics using R</li> </ul>"},{"location":"modules/cancer-module-viz/visu/#resources-youll-be-using","title":"Resources You\u2019ll be Using","text":""},{"location":"modules/cancer-module-viz/visu/#tools-used","title":"Tools Used","text":"<p>R: https://cran.r-project.org/</p> <p>R package circlize: https://cran.r-project.org/web/packages/circlize/index.html</p>"},{"location":"modules/cancer-module-viz/visu/#author-information","title":"Author Information","text":"<p>Primary Author(s): Mathieu Bourgey mathieu.bourgey@mcgill.ca </p> <p>Contributor(s): </p>"},{"location":"modules/cancer-module-viz/visu/#introduction","title":"Introduction","text":"<p>This short workshop will show you how to visualize your data.</p> <p>We will be working on 3 types of somatic calls:</p> <ul> <li> <p>SNV calls from MuTect (vcf)</p> </li> <li> <p>SV calls from DELLY (vcf)</p> </li> <li> <p>CNV calls from SCoNEs (tsv)</p> </li> </ul>"},{"location":"modules/cancer-module-viz/visu/#prepare-the-environment","title":"Prepare the Environment","text":"<p>We will use a dataset derived from the analysis of whole genome sequencing paired normal/tumour samples.</p> <p>The call files are contained in the folder <code>visualization</code>:</p> <ul> <li><code>mutect.somatic.vcf</code> </li> <li><code>delly.somatic.vcf</code> </li> <li><code>scones.somatic.tsv</code> </li> </ul> <p>Many tools are available to do this and the most commonly known is Circos. Circos is a really not user-friendly. In this tutorial, we show you an easy alternative to build a circular representation of genomic data.</p> <p>First we need to go in the folder <code>visualization</code> to do the analysis:</p> <pre><code>cd /home/trainee/visualization/\n</code></pre> <p>Let\u2019s see what is in this folder:</p> <pre><code>ls\n</code></pre> <p><code>circos.R  delly.somatic.vcf  mutect.somatic.vcf  scones.somatic.tsv</code></p> <p>Take a look at the data files.</p> <p>This data has not been restricted to a short piece of a chromosome and SNVs have already been filtered:</p> <p><pre><code>less mutect.somatic.vcf\nless delly.somatic.vcf\nless scones.somatic.tsv\n</code></pre> </p>  <p>Question</p> <p>What can you see from this data?</p>   Answer <ul> <li> <p>the filtered output of 3 different software: Mutect (SNVs), Delly (SVs), SCoNEs (CNVs).</p> </li> <li> <p>The 3 files show 2 different formats (vcf, tsv).</p> </li> <li> <p>Almost all type of variants are represented here: mutations, deletion, inversion, translocation, large amplification and deletion (CNVs).</p> </li> </ul>     <p>Question</p> <p>Why don\u2019t we use the vcf format for all types of calls?</p>   Answer <p>The 1000 Genomes project tries to use/include SV calls in the vcf format. Some tools like Delly use this format for SVs. It is a good idea to try to include everything together but this not the be the best way to handle SVs and CNVs.</p>     <p>Question</p> <p>Why?</p>   Answer <p>Due to the nature of these calls, you can not easily integrate the positional information of the two breakpoints (that could be located far away or in an other chromosome) using a single position format.</p>     <p>The analysis will be done using the R program:</p> <pre><code>R\n</code></pre> <p>We will use the circlize package from the cran R project. This package generates circular plots and has the advantage of being able to provide pre-built functions for genomic data. One of the main advantages of this tool is the use of bed format as input data.</p> <pre><code>library(circlize)\n</code></pre> <p> Let\u2019s import the variants:</p> <pre><code>snp=read.table(\"mutect.somatic.vcf\")\nsv=read.table(\"delly.somatic.vcf\")\ncnv=read.table(\"scones.somatic.tsv\",header=T)\n</code></pre> <p> We need to set up the generic graphical parameters:</p> <pre><code>x11()\npar(mar = c(1, 1, 1, 1))\ncircos.par(\"start.degree\" = 90)\ncircos.par(\"track.height\" = 0.05)\ncircos.par(\"canvas.xlim\" = c(-1.3, 1.3), \"canvas.ylim\" = c(-1.3, 1.3))\n</code></pre> <p> Let\u2019s draw hg19 reference ideograms:</p> <pre><code>circos.initializeWithIdeogram(species = \"hg19\")\n</code></pre> <p> We need to ensure our data to fits the hg19 standards so the main thing to check is that we have <code>chr</code> at the beginning of the chromosome names.</p> <p>We can now draw 1 track for somatic mutations:</p> <pre><code>snv_tmp=read.table(\"mutect.somatic.vcf\",comment.char=\"#\")\nsnv=cbind(paste(\"chr\",as.character(snp[,1]),sep=\"\"),snp[2],snp[,2]+1)\ncircos.genomicTrackPlotRegion(snv,stack=TRUE, panel.fun = function(region, value, ...) {\n    circos.genomicPoints(region, value, cex = 0.05, pch = 9,col='orange' , ...)\n})\n</code></pre> <p> Let\u2019s draw the 2 tracks for CNVs. One track for duplications in red and one blue track for deletions.</p> <pre><code>dup=cnv[cnv[,5]&gt;2,]\ndup[,1]=paste(\"chr\",as.character(dup[,1]),sep=\"\")\ndel=cnv[cnv[,5]&lt;2,]\ndel[,1]=paste(\"chr\",as.character(del[,1]),sep=\"\")\ncircos.genomicTrackPlotRegion(dup, stack = TRUE,panel.fun = function(region, value, ...) {\n        circos.genomicRect(region, value, col = \"red\",bg.border = NA, cex=1 , ...)\n})\ncircos.genomicTrackPlotRegion(del, stack = TRUE,panel.fun = function(region, value, ...) {\n        circos.genomicRect(region, value, col = \"blue\",bg.border = NA, cex=1 , ...)\n})\n</code></pre> <p>We can clearly see a massive deletion in chromosome 3.</p> <p> To finish we just need to draw 3 tracks + positional links to represent SVs.</p> <p>Unfortunately the vcf format has not been designed for SVs. SVs are defined by 2 breakpoints and the vcf format stores the second one in the info field. So we will need to extract this information to draw these calls.</p> <pre><code>chrEnd=NULL\nposEnd=NULL\nfor (i in 1:dim(sv)[1]) {\n    addInfo=strsplit(as.character(sv[i,8]),split=\";\")\n    chrInf=strsplit(addInfo[[1]][3],split=\"=\")\n    chrEnd=c(chrEnd,chrInf[[1]][2])\n    posInf=strsplit(addInfo[[1]][4],split=\"=\")\n    posEnd=c(posEnd,posInf[[1]][2])\n}\nsvTable=data.frame(paste(\"chr\",sv[,1],sep=\"\"),as.numeric(sv[,2]),as.numeric(posEnd),paste(\"chr\",chrEnd,sep=\"\"),as.character(sv[,5]))\n</code></pre> <p> Now that we have reformatted the SV calls, let\u2019s draw them.</p> <pre><code>typeE=c(\"&lt;DEL&gt;\",\"&lt;INS&gt;\",\"&lt;INV&gt;\")\ncolE=c(\"blue\",\"black\",\"green\")\nfor (i in 1:3) {\n        bed_list=svTable[svTable[,5]==typeE[i],]\n        circos.genomicTrackPlotRegion(bed_list,stack=TRUE, panel.fun = function(region, value, ...) {\n                circos.genomicPoints(region, value, cex = 0.5, pch = 16, col = colE[i], ...)\n        })\n}\n\nbed1=cbind(svTable[svTable[,5]==\"&lt;TRA&gt;\",1:2],svTable[svTable[,5]==\"&lt;TRA&gt;\",2]+5)\nbed2=cbind(svTable[svTable[,5]==\"&lt;TRA&gt;\",c(4,3)],svTable[svTable[,5]==\"&lt;TRA&gt;\",3]+5)\n\nfor (i in 1:dim(bed1)[1]) {\n    circos.link(bed1[i,1],bed1[i,2],bed2[i,1],bed2[i,2])\n}\n</code></pre> <p> A good graph needs a title and legend:</p> <pre><code>title(\"Somatic calls (SNV - SV - CNV)\")\nlegend(0.7,1.4,legend=c(\"SNV\", \"CNV-DUPLICATION\",\"CNV-DELETION\",\"SV-DELETION\",\"SV-INSERTION\",\"SV-INVERSION\"),col=c(\"orange\",\"red\",\"blue\",\"blue\",\"black\",\"green\",\"red\"),pch=c(16,15,15,16,16,16,16,16),cex=0.75,title=\"Tracks:\",bty='n')\nlegend(0.6,0.95,legend=\"SV-TRANSLOCATION\",col=\"black\",lty=1,cex=0.75,lwd=1.2,bty='n')\n</code></pre> <p> You should obtain a plot like this one:</p>  <p> Now save the image to the visualization directory as a .pdf:</p> <p><pre><code>dev.copy2pdf(file = \"/home/trainee/visualization/variant_visualization.pdf\")\ndev.off()\n</code></pre>  Finally exit R   <pre><code>q(\"yes\")\n</code></pre></p>"},{"location":"modules/cancer-module-viz/visu/#acknowledgements","title":"Acknowledgements","text":"<p>Mathieu Bourgey would like to thank and acknowledge Louis Letourneau for this help and for sharing his material. The format of the tutorial has been inspired from Mar Gonzalez Porta. I also want to acknowledge Joel Fillon, Louis Letrouneau (again), Francois Lefebvre, Maxime Caron and Guillaume Bourque for the help in building these pipelines and working with all the various datasets.</p>"},{"location":"modules/cancer-module-viz/visu/#license","title":"License","text":"<p>This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 Unported License. This means that you are able to copy, share and modify the work, as long as the result is distributed under the same license.</p>"},{"location":"timetables/timetable_cancer/","title":"Cancer Genomics Course","text":"<p>University of Sydney - 25th to 27th July 2017</p>"},{"location":"timetables/timetable_cancer/#instructors","title":"Instructors","text":"<ul> <li>Katherine Champ (KC)- Bioplatforms Australia, Sydney</li> <li>Ann-Marie Patch (AMP) - QIMR Berghofer, Brisbane</li> <li>Gayle Philip (GP) - Melbourne Bioinformatics, Melbourne</li> <li>Erdahl Teber (ET) - CMRI, Sydney</li> <li>Sonika Tyagi (ST) - Monash University, Melbourne</li> </ul>"},{"location":"timetables/timetable_cancer/#workshop-material","title":"Workshop Material","text":"<p>Material for the workshop can be found here.</p>"},{"location":"timetables/timetable_cancer/#timetable","title":"Timetable","text":""},{"location":"timetables/timetable_cancer/#day-1","title":"Day 1","text":"<p>25th July - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     9:00 Welcome  KC   9:15 Introduction to cancer genomics and NGS techniques \u2013 focus on DNA  AMP   10:15 Break     10:30 Experimental design (interactive/ice breaker/group activity) and caveats; considerations on processing capacities; 10 ways to ruin your experiment  AMP   11:30 Command line intro (Unix, R) \u2013 L(15\u2019) / P(30\u2019) [Practical][Commands in slides] GP   12:30 Lunch     13:30 Raw data - FASTQ format and QC  ST   14:00 Alignment (L)  ST   14:30 Practical: Manipulation of BAM files and QC [QC Practical][Alignment Practical] ST/GP   15:00 Coffee break     15:15 Practical: Manipulation of BAM files and QC (cont.)  GP/ST   17:00 Q&amp;A  All"},{"location":"timetables/timetable_cancer/#day-2","title":"Day 2","text":"<p>26th July - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     9:00 SNV detection (review, germline vs somatic, tools, pitfalls, data visualization) \u2013 L/P. Indels \u2013 cover in SNV lecture + bonus exercises (P), specific challenges of indels analysis, tools  ST   9:45 Practical: SNV detection [Practical] ST   10:30 Coffee break     10:45 Variants annotation and filtration (L) \u2013 tools landscape  ST   11:00 Practical: Variants visualization (IGV), annotation and filtration [Practical] ST   12:30 Lunch + coffee     13:30 CNV analysis using NGS data (L)  AMP   14:15 Practical: CNV analysis \u2013 deletion/amplification, calling CNVs, visualization, interpretation [Practical] GP/AMP   15:00 Break     15:15 Practical: CNV analysis \u2013 deletion/amplification, calling CNVs, visualization, interpretation (cont.)  GP/AMP   17:00 Q&amp;A  All"},{"location":"timetables/timetable_cancer/#day-3","title":"Day 3","text":"<p>27th July - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     9:00 SV analysis \u2013 breakpoints/fusion, tools  AMP   9:45 Practical: SV analysis \u2013 breakpoints/fusion [Practical] ET   10:30 Coffee break     10:45 Practical: SV analysis \u2013 breakpoints/fusion (cont.)  ET   12:30 Lunch     13:30 Downstream analysis and interpretation \u2013 Exploration of resources that can be used for this. E.g. databases (COSMIC, TCGA, etc.), integration with clinical information [Practical 1] [Practical 2] AMP   14:15 Practical: Downstream analysis and interpretation  AMP   15:00 Coffee break     15:15 Practical: Downstream analysis and interpretation(cont.)  AMP   16:00 How does it all link together? Integration of different data types  Mark Cowley   16:45 Q&amp;A, wrap up (how to access course\u2019s VM) &amp; survey  All"},{"location":"timetables/timetable_introNGS/","title":"Introduction to NGS Data Analysis Workshop","text":"<p>The University of Sydney, NSW - 27th - 29th June 2017</p>"},{"location":"timetables/timetable_introNGS/#instructors","title":"Instructors","text":"<ul> <li>Katherine Champ (KC) - Bioplatforms Australia, Sydney</li> <li>Sonika Tyagi (ST) - AGRF, Melbourne</li> <li>Matthew Field (MF) - Australian National University/James Cook University, Cairns</li> <li>Xi (Sean) Li (SL) - Australian National University, Canberra</li> <li>Susan Corley (SC) - UNSW Systems Biology Initiative, Sydney</li> </ul>"},{"location":"timetables/timetable_introNGS/#timetable","title":"Timetable","text":""},{"location":"timetables/timetable_introNGS/#day-1-introduction-to-the-command-line-data-quality-alignment-chip-seq","title":"Day 1 - Introduction to the command line, data quality &amp; alignment &amp; ChIP-Seq","text":"<p>27th June - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     09:00 Introductions and course orientation  K   09:45 Practical: Introduction to the command line     10:15 Morning Tea     10:40 Practical: Introduction to the command line course and R course     11:20 Introduction to NGS- technology, data formats and introduction to quality control     12:30 Lunch     13:15 Quality control: Intro to practical     13:25 Practical: Quality control     14:05 Introduction to sequence alignment     14:15 Practical: Sequence alignment     15:00 Afternoon Tea     15:25 Introduction to ChIP-Seq     15:55 Practical: ChIP-Seq analysis - Peak calling and annotation     16:30 Q&amp;A and day 1 wrap-up  All"},{"location":"timetables/timetable_introNGS/#day-2-chip-seq-motif-analysis-and-rna-seq-analysis","title":"Day 2 - ChIP-Seq motif analysis and RNA-Seq analysis","text":"<p>28th June - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     09:00 Practical: Motif analysis     09:40 Introduction to RNA-Seq     10:30 Morning Tea     10:50 Practical: Alignment and splice junction identification     12:30 Lunch     13:30 Practical: Differential gene expression with Bio-conductor package: EdgeR and Voom     15:00 Afternoon Tea     15:30 Practical: Biological interpretation     16:30 Q&amp;A and day 2 wrap-up  All"},{"location":"timetables/timetable_introNGS/#day-3-de-novo-assembly","title":"Day 3 - de novo Assembly","text":"<p>29th June - Computer Lab 1.4, Charles Perkins Centre, University of Sydney, NSW</p>    Time Topic Links Instructor     09:00 Introduction to de novo assembly     09:40 Practical: de novo assembly using Illumina reads     10:30 Morning Tea     10:50 Practical: de novo assembly using Illumina reads (cont.)     11:30 Practical: de novo assembly using PacBio \u2013 Canu workflow     12:30 Lunch     13:30 Practical: de novo assembly using PacBio \u2013 Canu workflow     15:30 Afternoon Tea     15:50 Practical: Polishing PacBio de novo assembly with Illumina reads     16:30 Q&amp;A and workshop wrap-up  All   17:00 Workshop Survey"},{"location":"timetables/timetable_longRead/","title":"Long-read Data Analysis Workshop","text":"<p>Sydney - 18th - 19th July 2017</p>"},{"location":"timetables/timetable_longRead/#instructors","title":"Instructors","text":"<ul> <li>Katherine Champ (KC) - Bioplatforms Australia, Sydney</li> <li>Tonia Russell (TR) - Ramaciotti Centre for Genomics, Sydney</li> <li>Anna Syme (AS) - Melbourne Bioinformatics, Melbourne</li> <li>Torsten Seemann (TS) - Melbourne Bioinformatics, Melbourne</li> <li>Nandan Deshpande - UNSW System Biology Initiative, Sydney</li> </ul>"},{"location":"timetables/timetable_longRead/#timetable","title":"Timetable","text":""},{"location":"timetables/timetable_longRead/#day-1","title":"Day 1","text":"<p>18th July - Room M020, The Red Centre, Kensington Campus, UNSW, Sydney</p>    Time Topic Links Instructor     9:00 Welcome and registration  Workshop Host and KC   9:30 Introduction to long-read sequencing (Lecture)  TS   10:30 Break     10:30 Long-read data \u2013 Practical considerations (Lecture)  TR   11:30 Introduction to Command-line (Practical)  ND   13:00 Lunch     14:00 Introduction to NGS \u2013 Technology, data formats and quality control  ND   14:30 Illumina de novo assembly (Velvet) (Practical)  ND   15:00 Coffee break     15:30 Illumina de novo assembly (Velvet) (Practical)  ND   17:00 Q&amp;A  All"},{"location":"timetables/timetable_longRead/#day-2","title":"Day 2","text":"<p>19th July - Room M020, The Red Centre, Kensington Campus, UNSW, Sydney</p>    Time Topic Links Instructor     9:00 Long-read data \u2013 Quality control (Practical)  TR   10:30 Coffee break     11:00 PacBio assembly + Illimuna polishing (Practical)  TS and AS   12:30 Lunch     13:30 PacBio assembly + Illimuna polishing (Continue) (Practical)  TS and AS   15:00 Break     15:30 Comparison of Illimuna and PacBio assembly  TS   16:45 Q&amp;A, wrap up (how to access course\u2019s VM) &amp; survey  All"},{"location":"trainers/trainers/","title":"The Trainers","text":"<p>  Dr. Ann-Marie Patch  Senior Research Officer  Medical Genomics QIMR Berghofer Medical Research Institute, Brisbane  </p> <p>  Dr. Gayle Philip  Research Fellow (Bioinformatics) Melbourne Bioinformatics, Carlton, Melbourne  </p>    <p>Dr. Erdahl Teber  Senior Research Officer (Bioinformatics) Children Medical Research Institute, Kids Cancer Alliance, University of Sydney, Sydney  </p> <p>  Dr. Sonika Tyagi  Bioinformatics Manager Monash Bioinformatics Platform, Monash University Melbourne </p>"},{"location":"trainers/trainers/#bioinformatics-training-platform-development","title":"Bioinformatics Training Platform Development","text":"<p>  Mr. Jerico Revote  Software Developer  Monash Bioinformatics Platform, Monash University, Clayton Melbourne  </p> <p>  Dr. Nathan S. Watson-Haigh  Research Fellow in Bioinformatics The Australian Centre for Plant Functional Genomics (ACPFG), Adelaide  </p>"},{"location":"trainers/trainers/#workshop-coordinator","title":"Workshop Coordinator","text":"<p>  Katherine Champ  Workshop Coordinator, Project Officer  Bioplatform Australia Ltd.  </p>"}]}